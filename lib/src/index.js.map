{"version":3,"sources":["../../src/index.js"],"names":["lexer","printAst","value","str","printAstRecursively","console","log","pre","undefined","constructor","name","children","length","nextPre","child","module","exports","parse","inputText","lexResult","tokenize","parser","tokens","statements","errors","Error","lexErrors","parseErrors"],"mappings":"AAAA;;AAEA;;IAAYA,K;;AACZ;;AACA;;;;AAEA;AACA,SAASC,QAAT,CAAkBC,KAAlB,EAAwB;AACtB,MAAIC,MAAMC,oBAAoBF,KAApB,EAA2B,EAA3B,EAA+B,EAA/B,CAAV;AACAG,UAAQC,GAAR,CAAYH,GAAZ;AACD;AACD,SAASC,mBAAT,CAA6BF,KAA7B,EAAoCK,GAApC,EAAyCJ,GAAzC,EAA6C;AAC3C,MAAGD,UAAUM,SAAb,EAAuB;AACrBL,WAAO,WAAP;AACA,WAAOA,GAAP;AACD,GAHD,MAGM,IAAGD,kCAAH,EAA0B;AAC9BC,WAAOD,MAAMO,WAAN,CAAkBC,IAAzB;AACA,WAAOP,GAAP;AACD;AACDA,SAAOD,MAAMQ,IAAb;AACA,MAAGR,MAAMS,QAAN,IAAkBT,MAAMS,QAAN,CAAeC,MAAf,GAAwB,CAA7C,EAA+C;AAC7C,QAAIC,UAAUN,MAAM,IAApB;AAD6C;AAAA;AAAA;;AAAA;AAE7C,2BAAiBL,MAAMS,QAAvB,8HAAgC;AAAA,YAAxBG,KAAwB;;AAC9BX,eAAO,OAAOU,OAAP,GAAiB,IAAxB;AACAV,cAAMC,oBAAoBU,KAApB,EAA2BD,OAA3B,EAAoCV,GAApC,CAAN;AACD;AAL4C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAM7CA,WAAO,OAAOI,GAAd;AACD;AACD,SAAOJ,GAAP;AACD;;AAEDY,OAAOC,OAAP,GAAiB;AACff,YAAWA,QADI;AAEfgB,SAAO,eAASC,SAAT,EAAmB;AACxB,QAAIC,YAAYnB,MAAMoB,QAAN,CAAeF,SAAf,CAAhB;AACA;AACA,QAAIG,SAAS,iCAAkBF,UAAUG,MAA5B,CAAb;AACA,QAAIpB,QAAQmB,OAAOE,UAAP,EAAZ;;AAEA,QAAIF,OAAOG,MAAP,CAAcZ,MAAd,GAAuB,CAA3B,EAA8B;AAC5BP,cAAQC,GAAR,CAAYe,OAAOG,MAAnB;AACC,YAAM,IAAIC,KAAJ,CAAU,wCAAV,CAAN;AACF;;AAED;;AAEA,WAAM;AACJvB,aAAaA,KADT,EACgB;AACpBwB,iBAAaP,UAAUK,MAFnB;AAGJG,mBAAaN,OAAOG;AAHhB,KAAN;AAKD;AApBc,CAAjB","file":"index.js","sourcesContent":["\"use strict\";\n\nimport * as lexer from './ArgdownLexer.js';\nimport {ArgdownParser} from \"./ArgdownParser.js\";\nimport {Token} from \"chevrotain\";\n\n//const parser = new ArgdownParser([]);\nfunction printAst(value){\n  let str = printAstRecursively(value, \"\", \"\");\n  console.log(str);\n}\nfunction printAstRecursively(value, pre, str){\n  if(value === undefined){\n    str += \"undefined\";\n    return str;\n  }else if(value instanceof Token){\n    str += value.constructor.name;\n    return str;\n  }\n  str += value.name;\n  if(value.children && value.children.length > 0){\n    let nextPre = pre + \" |\";\n    for(let child of value.children){\n      str += \"\\n\" + nextPre + \"__\";\n      str = printAstRecursively(child, nextPre, str);\n    }\n    str += \"\\n\" + pre;\n  }\n  return str;\n}\n\nmodule.exports = {\n  printAst : printAst,\n  parse: function(inputText){\n    let lexResult = lexer.tokenize(inputText);\n    //parser.input = lexResult.tokens;\n    let parser = new ArgdownParser(lexResult.tokens);\n    let value = parser.statements()\n\n    if (parser.errors.length > 0) {\n      console.log(parser.errors);\n       throw new Error(\"sad sad panda, Parsing errors detected\")\n    }\n\n    //printAst(value);\n\n    return{\n      value:       value, // this is a pure grammar, the value will always be <undefined>\n      lexErrors:   lexResult.errors,\n      parseErrors: parser.errors\n    };\n  }\n}\n"]}