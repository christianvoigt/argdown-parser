{"version":3,"sources":["../src/lexer.ts"],"names":["createToken","chevrotain","createTokenInstance","tokenMatcher","indentStack","rangesStack","tokenList","NEWLINE_GROUP","init","getCurrentLine","tokens","groups","nlGroup","matchedTokensIsEmpty","_","isEmpty","nlGroupIsEmpty","lastToken","last","lastNl","currentLine","endLine","Emptyline","getCurrentEndOffset","tokenEndOffset","endOffset","nlEndOffset","lastTokenIsNewline","newlineGroup","emitRemainingDedentTokens","matchedTokens","length","startOffset","startLine","startColumn","endColumn","push","Dedent","pop","emitIndentOrDedent","indentStr","currIndentLevel","lastIndentLevel","image","indentToken","Indent","dedentToken","matchRelation","text","offset","pattern","remainingText","substr","afterNewline","afterEmptyline","match","exec","matchIncomingSupport","partialRight","matchIncomingAttack","matchOutgoingSupport","matchOutgoingAttack","matchContradiction","matchIncomingUndercut","matchOutgoingUndercut","IncomingSupport","name","TokenNames","INCOMING_SUPPORT","line_breaks","label","start_chars_hint","IncomingAttack","INCOMING_ATTACK","OutgoingSupport","OUTGOING_SUPPORT","OutgoingAttack","OUTGOING_ATTACK","Contradiction","CONTRADICTION","IncomingUndercut","INCOMING_UNDERCUT","OutgoingUndercut","OUTGOING_UNDERCUT","inferenceStartPattern","matchInferenceStart","InferenceStart","INFERENCE_START","push_mode","FrontMatter","FRONT_MATTER","metaDataPattern","MetaData","META_DATA","ListDelimiter","LIST_DELIMITER","InferenceEnd","INFERENCE_END","pop_mode","matchListItem","orderedListItemPattern","matchOrderedListItem","OrderedListItem","ORDERED_LIST_ITEM","unorderedListItemPattern","matchUnorderedListItem","UnorderedListItem","UNORDERED_LIST_ITEM","emptylinePattern","matchEmptyline","EMPTYLINE","INDENT","Lexer","NA","DEDENT","StatementDefinition","STATEMENT_DEFINITION","StatementReference","STATEMENT_REFERENCE","StatementMention","STATEMENT_MENTION","statementNumberPattern","matchStatementNumber","StatementNumber","STATEMENT_NUMBER","ArgumentDefinition","ARGUMENT_DEFINITION","ArgumentReference","ARGUMENT_REFERENCE","ArgumentMention","ARGUMENT_MENTION","headingPattern","matchHeadingStart","HeadingStart","HEADING_START","matchBoldOrItalicStart","rangeType","matchBoldOrItalicEnd","lastRange","skipped","SKIPPED","lastSkipped","lastMatched","matchAsteriskBoldStart","matchAsteriskBoldEnd","matchUnderscoreBoldStart","matchUnderscoreBoldEnd","matchAsteriskItalicStart","matchAsteriskItalicEnd","matchUnderscoreItalicStart","matchUnderscoreItalicEnd","AsteriskBoldStart","ASTERISK_BOLD_START","AsteriskBoldEnd","ASTERISK_BOLD_END","UnderscoreBoldStart","UNDERSCORE_BOLD_START","UnderscoreBoldEnd","UNDERSCORE_BOLD_END","AsteriskItalicStart","ASTERISK_ITALIC_START","AsteriskItalicEnd","ASTERISK_ITALIC_END","UnderscoreItalicStart","UNDERSCORE_ITALIC_START","UnderscoreItalicEnd","UNDERSCORE_ITALIC_END","Comment","COMMENT","group","Link","LINK","Tag","TAG","Newline","NEWLINE","Spaces","SPACES","EscapedChar","ESCAPED_CHAR","Freestyle","FREESTYLE","UnusedControlChar","UNUSED_CONTROL_CHAR","EOF","lexerConfig","modes","default_mode","inference_mode","defaultMode","lexer","tokenize","lexResult","errors","Error"],"mappings":"AAAA;;;;;;;AAEA;;AACA;;AACA;;;;AAGA,IAAMA,cAAcC,WAAWD,WAA/B;AACA,IAAME,sBAAsBD,WAAWC,mBAAvC;AACA,IAAMC,eAAeF,WAAWE,YAAhC;AAGA;AACA,IAAIC,cAAwB,EAA5B,C,CACA;;AACA,IAAIC,cAAwB,EAA5B;AACO,IAAMC,YAAoC,EAA1C;;AACA,IAAMC,gBAAwB,UAA9B;;;AAEP,IAAMC,OAAO,SAAPA,IAAO,GAAM;AACjBJ,gBAAc,CAAC,CAAD,CAAd;AACAC,gBAAc,EAAd;AACD,CAHD;;AAIA,IAAMI,iBAAiB,SAAjBA,cAAiB,CAACC,MAAD,EAA8BC,MAA9B,EAAsD;AAC3E,MAAMC,UAAUD,OAAOJ,aAAP,CAAhB;;AACA,MAAMM,uBAAuBC,EAAEC,OAAF,CAAUL,MAAV,CAA7B;;AACA,MAAMM,iBAAiBF,EAAEC,OAAF,CAAUH,OAAV,CAAvB;;AACA,MAAIC,wBAAwBG,cAA5B,EAA4C,OAAO,CAAP;;AAE5C,MAAMC,YAAYH,EAAEI,IAAF,CAAOR,MAAP,CAAlB;;AACA,MAAMS,SAAcL,EAAEI,IAAF,CAAON,OAAP,CAApB;;AACA,MAAIQ,cAAcH,YAAYA,UAAUI,OAAtB,GAAiC,CAAnD;;AACA,MAAIJ,aAAahB,WAAWE,YAAX,CAAwBc,SAAxB,EAAmCK,SAAnC,CAAjB,EAAgE;AAC9DF;AACD;;AACD,MAAID,UAAUA,OAAOE,OAAP,GAAkB,CAAlB,GAAsBD,WAApC,EAAiD;AAC/CA,kBAAcD,OAAOE,OAAP,GAAkB,CAAhC;AACD;;AACD,SAAOD,WAAP;AACD,CAhBD;;AAiBA,IAAMG,sBAAsB,SAAtBA,mBAAsB,CAACb,MAAD,EAA8BC,MAA9B,EAAsD;AAChF,MAAMC,UAAUD,OAAOJ,aAAP,CAAhB;;AACA,MAAMM,uBAAuBC,EAAEC,OAAF,CAAUL,MAAV,CAA7B;;AACA,MAAMM,iBAAiBF,EAAEC,OAAF,CAAUH,OAAV,CAAvB;;AACA,MAAIC,wBAAwBG,cAA5B,EAA4C,OAAO,CAAP;;AAE5C,MAAMC,YAAYH,EAAEI,IAAF,CAAOR,MAAP,CAAlB;;AACA,MAAMS,SAAcL,EAAEI,IAAF,CAAON,OAAP,CAApB;;AACA,MAAMY,iBAAiBP,YAAYA,UAAUQ,SAAtB,GAAmC,CAA1D;AACA,MAAMC,cAAcP,SAASA,OAAOM,SAAhB,GAA6B,CAAjD;AACA,SAAOD,iBAAiBE,WAAjB,GAA+BF,cAA/B,GAAgDE,WAAvD;AACD,CAXD;;AAYA,IAAMC,qBAAqB,SAArBA,kBAAqB,CAACV,SAAD,EAA2CN,MAA3C,EAAoE;AAC7F,MAAMiB,eAAejB,OAAOJ,aAAP,CAArB;;AACA,MAAMY,SAAcL,EAAEI,IAAF,CAAOU,YAAP,CAApB;;AACA,SAAOT,WAAW,CAACF,SAAD,IAAcE,OAAOM,SAAP,GAAoBR,UAAUQ,SAAvD,CAAP;AACD,CAJD;;AAMA,IAAMI,4BAA4B,SAA5BA,yBAA4B,CAChCC,aADgC,EAEhCnB,MAFgC,EAGvB;AACT,MAAIP,YAAY2B,MAAZ,IAAsB,CAA1B,EAA6B;AAC3B;AACD;;AACD,MAAMd,YAAYH,EAAEI,IAAF,CAAOY,aAAP,CAAlB;;AACA,MAAME,cAAcT,oBAAoBO,aAApB,EAAmCnB,MAAnC,CAApB;AACA,MAAMc,YAAYO,WAAlB;AACA,MAAMC,YAAYxB,eAAeqB,aAAf,EAA8BnB,MAA9B,CAAlB;AACA,MAAMU,UAAUY,SAAhB;AACA,MAAMC,cAAcjB,aAAaA,UAAUkB,SAAvB,GAAmClB,UAAUkB,SAA7C,GAAyD,CAA7E;AACA,MAAMA,YAAYD,WAAlB,CAVS,CAYT;;AACA,SAAO9B,YAAY2B,MAAZ,GAAqB,CAA5B,EAA+B;AAC7BD,kBAAcM,IAAd,CACElC,oBAAoBmC,MAApB,EAA4B,EAA5B,EAAgCL,WAAhC,EAA6CP,SAA7C,EAAwDQ,SAAxD,EAAmEZ,OAAnE,EAA4Ea,WAA5E,EAAyFC,SAAzF,CADF;AAGA/B,gBAAYkC,GAAZ;AACD;AACF,CAtBD;;AAwBA,IAAMC,qBAAqB,SAArBA,kBAAqB,CACzBT,aADyB,EAEzBnB,MAFyB,EAGzB6B,SAHyB,EAIhB;AACT,MAAMC,kBAAkBD,UAAUT,MAAlC;AACA,MAAIW,kBAAkB5B,EAAEI,IAAF,CAAOd,WAAP,KAAuB,CAA7C;AACA,MAAMuC,QAAQ,EAAd;AACA,MAAMX,cAAcT,oBAAoBO,aAApB,EAAmCnB,MAAnC,IAA6C,CAAjE;AACA,MAAMc,YAAYO,cAAcQ,UAAUT,MAAxB,GAAiC,CAAnD;AACA,MAAME,YAAYxB,eAAeqB,aAAf,EAA8BnB,MAA9B,CAAlB;AACA,MAAMU,UAAUY,SAAhB;AACA,MAAMC,cAAc,CAApB;AACA,MAAMC,YAAYD,cAAcM,UAAUT,MAAxB,GAAiC,CAAnD;;AACA,MAAIU,kBAAkBC,eAAtB,EAAuC;AACrCtC,gBAAYgC,IAAZ,CAAiBK,eAAjB;AACA,QAAIG,cAAc1C,oBAChB2C,MADgB,EAEhBF,KAFgB,EAGhBX,WAHgB,EAIhBP,SAJgB,EAKhBQ,SALgB,EAMhBZ,OANgB,EAOhBa,WAPgB,EAQhBC,SARgB,CAAlB;AAUAL,kBAAcM,IAAd,CAAmBQ,WAAnB;AACD,GAbD,MAaO,IAAIH,kBAAkBC,eAAtB,EAAuC;AAC5C,WAAOtC,YAAY2B,MAAZ,GAAqB,CAArB,IAA0BU,kBAAkBC,eAAnD,EAAoE;AAClEtC,kBAAYkC,GAAZ;AACAI,wBAAkB5B,EAAEI,IAAF,CAAOd,WAAP,KAAuB,CAAzC;AACA,UAAI0C,cAAc5C,oBAChBmC,MADgB,EAEhBM,KAFgB,EAGhBX,WAHgB,EAIhBP,SAJgB,EAKhBQ,SALgB,EAMhBZ,OANgB,EAOhBa,WAPgB,EAQhBC,SARgB,CAAlB;AAUAL,oBAAcM,IAAd,CAAmBU,WAAnB;AACD;AACF;AACF,CA5CD;;AA6CA,IAAMC,gBAAgB,SAAhBA,aAAgB,CACpBC,IADoB,EAEpBC,MAFoB,EAGpBvC,MAHoB,EAIpBC,MAJoB,EAKpBuC,OALoB,EAMjB;AACH,MAAMC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAAtB;;AACA,MAAMhC,YAAYH,EAAEI,IAAF,CAAOR,MAAP,CAAlB;;AACA,MAAM2C,eAAe1B,mBAAmBV,SAAnB,EAA8BN,MAA9B,CAArB;AACA,MAAM2C,iBAAiBrC,aAAad,aAAac,SAAb,EAAwBK,SAAxB,CAApC;;AAEA,MAAIR,EAAEC,OAAF,CAAUL,MAAV,KAAqB4C,cAArB,IAAuCD,YAA3C,EAAyD;AACvD;AACA,QAAIE,QAAQL,QAASM,IAAT,CAAcL,aAAd,CAAZ;;AACA,QAAII,UAAU,IAAV,IAAkBA,MAAMxB,MAAN,IAAgB,CAAtC,EAAyC;AACvC,UAAMS,YAAYe,MAAM,CAAN,CAAlB;AACAhB,yBAAmB7B,MAAnB,EAAiCC,MAAjC,EAA0C6B,SAA1C;AACA,aAAOe,KAAP;AACD;AACF;;AACD,SAAO,IAAP;AACD,CAtBD,C,CAuBA;;;AACA,IAAME,uBAAuB3C,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,kBAA9B,CAA7B;;AACA,IAAMY,sBAAsB7C,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,iBAA9B,CAA5B;;AACA,IAAMa,uBAAuB9C,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,mBAA9B,CAA7B;;AACA,IAAMc,sBAAsB/C,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,kBAA9B,CAA5B;;AACA,IAAMe,qBAAqBhD,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,iBAA9B,CAA3B;;AACA,IAAMgB,wBAAwBjD,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,iBAA9B,CAA9B;;AACA,IAAMiB,wBAAwBlD,EAAE4C,YAAF,CAAeX,aAAf,EAA8B,iBAA9B,CAA9B;;AAEO,IAAMkB,kBAAkBjE,YAAY;AACzCkE,QAAMC,uBAAWC,gBADwB;AAEzClB,WAASO,oBAFgC;AAGzCY,eAAa,IAH4B;AAIzCC,SAAO,uBAJkC;AAKzCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALuB,CAAZ,CAAxB;;AAOPjE,UAAU8B,IAAV,CAAe6B,eAAf;AAEO,IAAMO,iBAAiBxE,YAAY;AACxCkE,QAAMC,uBAAWM,eADuB;AAExCvB,WAASS,mBAF+B;AAGxCU,eAAa,IAH2B;AAIxCC,SAAO,sBAJiC;AAKxCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALsB,CAAZ,CAAvB;;AAOPjE,UAAU8B,IAAV,CAAeoC,cAAf;AAEO,IAAME,kBAAkB1E,YAAY;AACzCkE,QAAMC,uBAAWQ,gBADwB;AAEzCzB,WAASU,oBAFgC;AAGzCS,eAAa,IAH4B;AAIzCC,SAAO,uBAJkC;AAKzCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALuB,CAAZ,CAAxB;;AAOPjE,UAAU8B,IAAV,CAAesC,eAAf;AAEO,IAAME,iBAAiB5E,YAAY;AACxCkE,QAAMC,uBAAWU,eADuB;AAExC3B,WAASW,mBAF+B;AAGxCQ,eAAa,IAH2B;AAIxCC,SAAO,sBAJiC;AAKxCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALsB,CAAZ,CAAvB;;AAOPjE,UAAU8B,IAAV,CAAewC,cAAf;AAEO,IAAME,gBAAgB9E,YAAY;AACvCkE,QAAMC,uBAAWY,aADsB;AAEvC7B,WAASY,kBAF8B;AAGvCO,eAAa,IAH0B;AAIvCC,SAAO,oBAJgC;AAKvCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALqB,CAAZ,CAAtB;;AAOPjE,UAAU8B,IAAV,CAAe0C,aAAf;AACO,IAAME,mBAAmBhF,YAAY;AAC1CkE,QAAMC,uBAAWc,iBADyB;AAE1C/B,WAASa,qBAFiC;AAG1CM,eAAa,IAH6B;AAI1CC,SAAO,wBAJmC;AAK1CC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALwB,CAAZ,CAAzB;;AAOPjE,UAAU8B,IAAV,CAAe4C,gBAAf;AACO,IAAME,mBAAmBlF,YAAY;AAC1CkE,QAAMC,uBAAWgB,iBADyB;AAE1CjC,WAASc,qBAFiC;AAG1CK,eAAa,IAH6B;AAI1CC,SAAO,wBAJmC;AAK1CC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALwB,CAAZ,CAAzB;;AAOPjE,UAAU8B,IAAV,CAAe8C,gBAAf;AAEA,IAAME,wBAAwB,eAA9B;;AAEA,IAAMC,sBAA2D,SAA3DA,mBAA2D,CAACrC,IAAD,EAAOC,MAAP,EAAevC,MAAf,EAAuBC,MAAvB,EAAkC;AACjG,MAAIwC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;;AACA,MAAMhC,YAAYH,EAAEI,IAAF,CAAOR,MAAP,CAAlB;;AACA,MAAI2C,eAAe1B,mBAAmBV,SAAnB,EAA8BN,MAA9B,CAAnB;;AACA,MAAIG,EAAEC,OAAF,CAAUL,MAAV,KAAqB2C,YAAzB,EAAuC;AACrC,QAAME,QAAQ6B,sBAAsB5B,IAAtB,CAA2BL,aAA3B,CAAd;;AACA,QAAII,SAAS,IAAb,EAAmB;AACjB1B,gCAA0BnB,MAA1B,EAAwCC,MAAxC;AACA,aAAO4C,KAAP;AACD;AACF;;AACD,SAAO,IAAP;AACD,CAZD;;AAcO,IAAM+B,iBAAiBtF,YAAY;AACxCkE,QAAMC,uBAAWoB,eADuB;AAExCrC,WAASmC,mBAF+B;AAGxCG,aAAW,gBAH6B;AAIxCnB,eAAa,IAJ2B;AAKxCC,SAAO,sBALiC;AAMxCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AANsB,CAAZ,CAAvB;;AAQPjE,UAAU8B,IAAV,CAAekD,cAAf;AAEO,IAAMG,cAAczF,YAAY;AACrCkE,QAAMC,uBAAWuB,YADoB;AAErCxC,WAAS,aAF4B;AAGrCoB,SAAO;AAH8B,CAAZ,CAApB;;AAKPhE,UAAU8B,IAAV,CAAeqD,WAAf;AAEA,IAAME,kBAAkB,uCAAxB,C,CACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACO,IAAMC,WAAW5F,YAAY;AAClCkE,QAAMC,uBAAW0B,SADiB;AAElC3C,WAAS,uCAFyB;AAGlCoB,SAAO;AAH2B,CAAZ,CAAjB;;AAKPhE,UAAU8B,IAAV,CAAewD,QAAf;AACO,IAAME,gBAAgB9F,YAAY;AACvCkE,QAAMC,uBAAW4B,cADsB;AAEvC7C,WAAS,GAF8B;AAGvCoB,SAAO;AAHgC,CAAZ,CAAtB;;AAKPhE,UAAU8B,IAAV,CAAe0D,aAAf,E,CACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO,IAAME,eAAehG,YAAY;AACtCkE,QAAMC,uBAAW8B,aADqB;AAEtC/C,WAAS,OAF6B;AAGtCgD,YAAU,IAH4B;AAItC5B,SAAO;AAJ+B,CAAZ,CAArB;;AAMPhE,UAAU8B,IAAV,CAAe4D,YAAf;;AAEA,IAAMG,gBAAgB,SAAhBA,aAAgB,CACpBnD,IADoB,EAEpBC,MAFoB,EAGpBvC,MAHoB,EAIpBC,MAJoB,EAKpBuC,OALoB,EAMO;AAC3B,MAAIC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;;AACA,MAAI/B,OAAOJ,EAAEI,IAAF,CAAOR,MAAP,CAAX;;AACA,MAAI2C,eAAe1B,mBAAmBT,IAAnB,EAAyBP,MAAzB,CAAnB;AACA,MAAI2C,iBAAiBpC,QAAQf,aAAae,IAAb,EAAmBI,SAAnB,CAA7B;;AACA,MAAIR,EAAEC,OAAF,CAAUL,MAAV,KAAqB4C,cAArB,IAAuCD,YAA3C,EAAyD;AACvD,QAAIE,QAAQL,QAASM,IAAT,CAAcL,aAAd,CAAZ;;AACA,QAAII,UAAU,IAAd,EAAoB;AAClB,UAAMf,YAAYe,MAAM,CAAN,CAAlB;AACAhB,yBAAmB7B,MAAnB,EAA4BC,MAA5B,EAAqC6B,SAArC;AACA,aAAOe,KAAP;AACD;AACF;;AACD,SAAO,IAAP;AACD,CApBD;;AAsBA,IAAM6C,yBAAyB,wBAA/B;;AACA,IAAMC,uBAAuBvF,EAAE4C,YAAF,CAAeyC,aAAf,EAA8BC,sBAA9B,CAA7B;;AAEO,IAAME,kBAAkBtG,YAAY;AACzCkE,QAAMC,uBAAWoC,iBADwB;AAEzCrD,WAASmD,oBAFgC;AAGzChC,eAAa,IAH4B;AAIzCC,SAAO,4CAJkC;AAKzCC,oBAAkB,CAAC,GAAD,EAAM,IAAN;AALuB,CAAZ,CAAxB;;AAOPjE,UAAU8B,IAAV,CAAekE,eAAf,E,CACA;;AACA,IAAME,2BAA2B,qBAAjC;;AACA,IAAMC,yBAAyB3F,EAAE4C,YAAF,CAAeyC,aAAf,EAA8BK,wBAA9B,CAA/B;;AAEO,IAAME,oBAAoB1G,YAAY;AAC3CkE,QAAMC,uBAAWwC,mBAD0B;AAE3CzD,WAASuD,sBAFkC;AAG3CpC,eAAa,IAH8B;AAI3CC,SAAO,sCAJoC;AAK3CC,oBAAkB,CAAC,GAAD,EAAM,IAAN;AALyB,CAAZ,CAA1B;;AAOPjE,UAAU8B,IAAV,CAAesE,iBAAf,E,CAEA;AACA;;AACA,IAAME,mBAAmB,kCAAzB,C,CAA6D;;AAC7D,IAAMC,iBAAiB,SAAjBA,cAAiB,CAAC7D,IAAD,EAAeC,MAAf,EAAgCvC,MAAhC,EAA8DC,MAA9D,EAAkF;AACvG,MAAIwC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;;AACA,MAAI/B,OAAOJ,EAAEI,IAAF,CAAOR,MAAP,CAAX,CAFuG,CAGvG;;;AACA,MAAIQ,QAAQf,aAAae,IAAb,EAAmBI,SAAnB,CAAZ,EAA2C,OAAO,IAAP;AAC3C,MAAIiC,QAAQqD,iBAAiBpD,IAAjB,CAAsBL,aAAtB,CAAZ;;AACA,MAAII,UAAU,IAAV,IAAkBA,MAAM,CAAN,EAASxB,MAAT,GAAkBoB,cAAcpB,MAAtD,EAA8D;AAC5D;AACAF,8BAA0BnB,MAA1B,EAAwCC,MAAxC,EAF4D,CAG5D;;AACA,WAAO4C,KAAP;AACD;;AACD,SAAO,IAAP;AACD,CAbD;;AAcO,IAAMjC,YAAYtB,YAAY;AACnCkE,QAAMC,uBAAW2C,SADkB;AAEnC5D,WAAS2D,cAF0B;AAGnCxC,eAAa,IAHsB;AAInCC,SAAO,qCAJ4B;AAKnCC,oBAAkB,CAAC,IAAD,EAAO,IAAP;AALiB,CAAZ,CAAlB;;AAOPjE,UAAU8B,IAAV,CAAed,SAAf,E,CAEA;;AACO,IAAMuB,SAAS7C,YAAY;AAChCkE,QAAMC,uBAAW4C,MADe;AAEhC7D,WAASjD,WAAW+G,KAAX,CAAiBC;AAFM,CAAZ,CAAf;;AAIP3G,UAAU8B,IAAV,CAAeS,MAAf;AAEO,IAAMR,SAASrC,YAAY;AAChCkE,QAAMC,uBAAW+C,MADe;AAEhChE,WAASjD,WAAW+G,KAAX,CAAiBC;AAFM,CAAZ,CAAf;;AAIP3G,UAAU8B,IAAV,CAAeC,MAAf;AAEO,IAAM8E,sBAAsBnH,YAAY;AAC7CkE,QAAMC,uBAAWiD,oBAD4B;AAE7ClE,WAAS,WAFoC;AAG7CoB,SAAO;AAHsC,CAAZ,CAA5B;;AAKPhE,UAAU8B,IAAV,CAAe+E,mBAAf,E,CAEA;AACA;AACA;AACA;AACA;;AAEO,IAAME,qBAAqBrH,YAAY;AAC5CkE,QAAMC,uBAAWmD,mBAD2B;AAE5CpE,WAAS,SAFmC;AAG5CoB,SAAO;AAHqC,CAAZ,CAA3B;;AAKPhE,UAAU8B,IAAV,CAAeiF,kBAAf,E,CAEA;AACA;AACA;AACA;AACA;;AAEO,IAAME,mBAAmBvH,YAAY;AAC1CkE,QAAMC,uBAAWqD,iBADyB;AAE1CtE,WAAS,iBAFiC;AAG1CoB,SAAO;AAHmC,CAAZ,CAAzB;;AAKPhE,UAAU8B,IAAV,CAAemF,gBAAf,E,CAEA;AACA;AACA;AACA;AACA;;AAEA,IAAME,yBAAyB,kBAA/B;;AACA,IAAMC,uBAAuB,SAAvBA,oBAAuB,CAAC1E,IAAD,EAAeC,MAAf,EAAgCvC,MAAhC,EAA8DC,MAA9D,EAAkF;AAC7G,MAAIwC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;;AACA,MAAI/B,OAAOJ,EAAEI,IAAF,CAAOR,MAAP,CAAX;;AACA,MAAI2C,eAAe1B,mBAAmBT,IAAnB,EAAyBP,MAAzB,CAAnB;AACA,MAAI2C,iBAAiBpC,QAAQf,aAAae,IAAb,EAAmBI,SAAnB,CAA7B,CAJ6G,CAM7G;;AACA,MAAIR,EAAEC,OAAF,CAAUL,MAAV,KAAqB4C,cAArB,IAAuCD,YAA3C,EAAyD;AACvD,QAAIE,QAAQkE,uBAAuBjE,IAAvB,CAA4BL,aAA5B,CAAZ;;AACA,QAAII,UAAU,IAAd,EAAoB;AAClB1B,gCAA0BnB,MAA1B,EAAwCC,MAAxC;AACA,aAAO4C,KAAP;AACD;AACF;;AACD,SAAO,IAAP;AACD,CAfD;;AAgBO,IAAMoE,kBAAkB3H,YAAY;AACzCkE,QAAMC,uBAAWyD,gBADwB;AAEzC1E,WAASwE,oBAFgC;AAGzCrD,eAAa,IAH4B;AAIzCC,SAAO,6BAJkC;AAKzCC,oBAAkB,CAAC,GAAD,EAAM,IAAN,EAAY,GAAZ;AALuB,CAAZ,CAAxB;;AAOPjE,UAAU8B,IAAV,CAAeuF,eAAf;AAEO,IAAME,qBAAqB7H,YAAY;AAC5CkE,QAAMC,uBAAW2D,mBAD2B;AAE5C5E,WAAS,WAFmC;AAG5CoB,SAAO;AAHqC,CAAZ,CAA3B;;AAKPhE,UAAU8B,IAAV,CAAeyF,kBAAf;AAEO,IAAME,oBAAoB/H,YAAY;AAC3CkE,QAAMC,uBAAW6D,kBAD0B;AAE3C9E,WAAS,SAFkC;AAG3CoB,SAAO;AAHoC,CAAZ,CAA1B;;AAKPhE,UAAU8B,IAAV,CAAe2F,iBAAf;AAEO,IAAME,kBAAkBjI,YAAY;AACzCkE,QAAMC,uBAAW+D,gBADwB;AAEzChF,WAAS,iBAFgC;AAGzCoB,SAAO;AAHkC,CAAZ,CAAxB;;AAKPhE,UAAU8B,IAAV,CAAe6F,eAAf;AAEA,IAAME,iBAAiB,YAAvB;;AACA,IAAMC,oBAAoB,SAApBA,iBAAoB,CAACpF,IAAD,EAAeC,MAAf,EAAgCvC,MAAhC,EAA8DC,MAA9D,EAAkF;AAC1G,MAAIwC,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;;AACA,MAAI/B,OAAOJ,EAAEI,IAAF,CAAOR,MAAP,CAAX;;AACA,MAAI4C,iBAAiBpC,QAAQf,aAAae,IAAb,EAAmBI,SAAnB,CAA7B;;AAEA,MAAI,CAACJ,IAAD,IAASoC,cAAb,EAA6B;AAC3B,QAAMC,QAAQ4E,eAAe3E,IAAf,CAAoBL,aAApB,CAAd;;AACA,QAAII,KAAJ,EAAW;AACT,aAAOA,KAAP;AACD;AACF;;AACD,SAAO,IAAP;AACD,CAZD;;AAaO,IAAM8E,eAAerI,YAAY;AACtCkE,QAAMC,uBAAWmE,aADqB;AAEtCpF,WAASkF,iBAF6B;AAGtC9D,SAAO,mBAH+B;AAItCC,oBAAkB,CAAC,GAAD;AAJoB,CAAZ,CAArB;;AAMPjE,UAAU8B,IAAV,CAAeiG,YAAf,E,CAEA;;AACA,IAAME,yBAAyB,SAAzBA,sBAAyB,CAC7BvF,IAD6B,EAE7BC,MAF6B,EAG7BvC,MAH6B,EAI7BC,MAJ6B,EAK7BuC,OAL6B,EAM7BsF,SAN6B,EAO1B;AACH,MAAIrF,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;AACA,MAAIM,QAAQL,QAASM,IAAT,CAAcL,aAAd,CAAZ;;AACA,MAAII,SAAS,IAAb,EAAmB;AACjBlD,gBAAY+B,IAAZ,CAAiBoG,SAAjB;AACA,WAAOjF,KAAP;AACD;;AACD,SAAO,IAAP;AACD,CAfD;;AAiBA,IAAMkF,uBAAuB,SAAvBA,oBAAuB,CAC3BzF,IAD2B,EAE3BC,MAF2B,EAG3BvC,MAH2B,EAI3BC,MAJ2B,EAK3BuC,OAL2B,EAM3BsF,SAN2B,EAOA;AAC3B,MAAIE,YAAY5H,EAAEI,IAAF,CAAOb,WAAP,CAAhB;;AACA,MAAIqI,aAAaF,SAAjB,EAA4B,OAAO,IAAP,CAFD,CAG3B;;AACA,MAAIG,UAAehI,SAASA,OAAOV,WAAW+G,KAAX,CAAiB4B,OAAxB,CAAT,GAA4C,IAA/D;;AACA,MAAIC,cAAmB/H,EAAEI,IAAF,CAAOyH,OAAP,CAAvB;;AACA,MAAIG,cAAchI,EAAEI,IAAF,CAAOR,MAAP,CAAlB;;AACA,MAAI,CAACoI,WAAD,IAAiBD,eAAeA,YAAYpH,SAAZ,GAAyBqH,YAAYrH,SAAzE,EAAsF;AACpF,WAAO,IAAP;AACD;;AACD,MAAI0B,gBAAgBH,KAAKI,MAAL,CAAYH,UAAU,CAAtB,CAApB;AACA,MAAIM,QAAQL,QAASM,IAAT,CAAcL,aAAd,CAAZ;;AAEA,MAAII,SAAS,IAAb,EAAmB;AACjBlD,gBAAYiC,GAAZ;AACA,WAAOiB,KAAP;AACD;;AACD,SAAO,IAAP;AACD,CAzBD;;AA0BA,IAAMwF,yBAAyBjI,EAAE4C,YAAF,CAAe6E,sBAAf,EAAuC,aAAvC,EAAsD,cAAtD,CAA/B;;AACA,IAAMS,uBAAuBlI,EAAE4C,YAAF,CAC3B+E,oBAD2B,EAE3B,wDAF2B,EAG3B,cAH2B,CAA7B;;AAMA,IAAMQ,2BAA2BnI,EAAE4C,YAAF,CAAe6E,sBAAf,EAAuC,WAAvC,EAAoD,gBAApD,CAAjC;;AACA,IAAMW,yBAAyBpI,EAAE4C,YAAF,CAC7B+E,oBAD6B,EAE7B,sDAF6B,EAG7B,gBAH6B,CAA/B;;AAMA,IAAMU,2BAA2BrI,EAAE4C,YAAF,CAAe6E,sBAAf,EAAuC,WAAvC,EAAoD,gBAApD,CAAjC;;AACA,IAAMa,yBAAyBtI,EAAE4C,YAAF,CAC7B+E,oBAD6B,EAE7B,sDAF6B,EAG7B,gBAH6B,CAA/B;;AAMA,IAAMY,6BAA6BvI,EAAE4C,YAAF,CAAe6E,sBAAf,EAAuC,WAAvC,EAAoD,kBAApD,CAAnC;;AACA,IAAMe,2BAA2BxI,EAAE4C,YAAF,CAC/B+E,oBAD+B,EAE/B,sDAF+B,EAG/B,kBAH+B,CAAjC;;AAMO,IAAMc,oBAAoBvJ,YAAY;AAC3CkE,QAAMC,uBAAWqF,mBAD0B;AAE3CtG,WAAS6F,sBAFkC;AAG3CzE,SAAO,iBAHoC;AAI3CC,oBAAkB,CAAC,GAAD;AAJyB,CAAZ,CAA1B;;AAMPjE,UAAU8B,IAAV,CAAemH,iBAAf;AAEO,IAAME,kBAAkBzJ,YAAY;AACzCkE,QAAMC,uBAAWuF,iBADwB;AAEzCxG,WAAS8F,oBAFgC;AAGzC1E,SAAO,eAHkC;AAIzCC,oBAAkB,CAAC,GAAD;AAJuB,CAAZ,CAAxB;;AAMPjE,UAAU8B,IAAV,CAAeqH,eAAf;AAEO,IAAME,sBAAsB3J,YAAY;AACtCkE,QAAMC,uBAAWyF,qBADqB;AAEtC1G,WAAS+F,wBAF6B;AAGtC3E,SAAO,iBAH+B;AAItCC,oBAAkB,CAAC,GAAD;AAJoB,CAAZ,CAA5B;;AAMPjE,UAAU8B,IAAV,CAAeuH,mBAAf;AAEO,IAAME,oBAAoB7J,YAAY;AACpCkE,QAAMC,uBAAW2F,mBADmB;AAEpC5G,WAASgG,sBAF2B;AAGpC5E,SAAO,eAH6B;AAIpCC,oBAAkB,CAAC,GAAD;AAJkB,CAAZ,CAA1B;;AAMPjE,UAAU8B,IAAV,CAAeyH,iBAAf;AAEO,IAAME,sBAAsB/J,YAAY;AACtCkE,QAAMC,uBAAW6F,qBADqB;AAEtC9G,WAASiG,wBAF6B;AAGtC7E,SAAO,kBAH+B;AAItCC,oBAAkB,CAAC,GAAD;AAJoB,CAAZ,CAA5B;;AAMPjE,UAAU8B,IAAV,CAAe2H,mBAAf;AAEO,IAAME,oBAAoBjK,YAAY;AAC3CkE,QAAMC,uBAAW+F,mBAD0B;AAE3ChH,WAASkG,sBAFkC;AAG3C9E,SAAO,gBAHoC;AAI3CC,oBAAkB,CAAC,GAAD;AAJyB,CAAZ,CAA1B;;AAMPjE,UAAU8B,IAAV,CAAe6H,iBAAf;AAEO,IAAME,wBAAwBnK,YAAY;AAC/CkE,QAAMC,uBAAWiG,uBAD8B;AAE/ClH,WAASmG,0BAFsC;AAG/C/E,SAAO,kBAHwC;AAI/CC,oBAAkB,CAAC,GAAD;AAJ6B,CAAZ,CAA9B;;AAMPjE,UAAU8B,IAAV,CAAe+H,qBAAf;AAEO,IAAME,sBAAsBrK,YAAY;AAC7CkE,QAAMC,uBAAWmG,qBAD4B;AAE7CpH,WAASoG,wBAFoC;AAG7ChF,SAAO,gBAHsC;AAI7CC,oBAAkB,CAAC,GAAD;AAJ2B,CAAZ,CAA5B;;AAMPjE,UAAU8B,IAAV,CAAeiI,mBAAf;AAEO,IAAME,UAAUvK,YAAY;AACjCkE,QAAMC,uBAAWqG,OADgB;AAEjCtH,WAAS,8EAFwB;AAGjCuH,SAAOxK,WAAW+G,KAAX,CAAiB4B,OAHS;AAIjCvE,eAAa,IAJoB;AAKjCC,SAAO;AAL0B,CAAZ,CAAhB;;AAOPhE,UAAU8B,IAAV,CAAemI,OAAf;AAEO,IAAMG,OAAO1K,YAAY;AAC9BkE,QAAMC,uBAAWwG,IADa;AAE9BzH,WAAS,8BAFqB;AAG9BoB,SAAO;AAHuB,CAAZ,CAAb;;AAKPhE,UAAU8B,IAAV,CAAesI,IAAf;AAEO,IAAME,MAAM5K,YAAY;AAC7BkE,QAAMC,uBAAW0G,GADY;AAE7B3H,WAAS,4EAFoB;AAG7BoB,SAAO;AAHsB,CAAZ,CAAZ;;AAKPhE,UAAU8B,IAAV,CAAewI,GAAf;AAEO,IAAME,UAAU9K,YAAY;AACjCkE,QAAMC,uBAAW4G,OADgB;AAEjC7H,WAAS,gBAFwB;AAGjCuH,SAAO,UAH0B;AAIjCpG,eAAa,IAJoB;AAKjCC,SAAO;AAL0B,CAAZ,CAAhB;;AAOPhE,UAAU8B,IAAV,CAAe0I,OAAf;AAEO,IAAME,SAAShL,YAAY;AAChCkE,QAAMC,uBAAW8G,MADe;AAEhC/H,WAAS,SAFuB;AAGhCuH,SAAOxK,WAAW+G,KAAX,CAAiB4B;AAHQ,CAAZ,CAAf;;AAKPtI,UAAU8B,IAAV,CAAe4I,MAAf;AAEO,IAAME,cAAclL,YAAY;AACrCkE,QAAMC,uBAAWgH,YADoB;AAErCjI,WAAS,WAF4B;AAGrCoB,SAAO;AAH8B,CAAZ,CAApB;;AAKPhE,UAAU8B,IAAV,CAAe8I,WAAf,E,CAEA;;AACO,IAAME,YAAYpL,YAAY;AACnCkE,QAAMC,uBAAWkH,SADkB;AAEnCnI,WAAS,8CAF0B;AAGnCmB,eAAa,IAHsB;AAInCC,SAAO;AAJ4B,CAAZ,CAAlB;;AAMPhE,UAAU8B,IAAV,CAAegJ,SAAf,E,CAEA;AACA;AACA;AACA;;AACO,IAAME,oBAAoBtL,YAAY;AAC3CkE,QAAMC,uBAAWoH,mBAD0B;AAE3CrI,WAAS,4CAFkC;AAG3CoB,SAAO;AAHoC,CAAZ,CAA1B;;AAKPhE,UAAU8B,IAAV,CAAekJ,iBAAf;AAEO,IAAME,MAAMvL,WAAWuL,GAAvB;;AAEP,IAAMC,cAAoD;AACxDC,SAAO;AACLC,kBAAc,CACZpB,OADY,EAEZ9E,WAFY,EAGZG,QAHY,EAIZsF,WAJY,EAIC;AACb5J,aALY,EAMZwJ,OANY,EAOZ;AACA;AACAzI,UATY,EAUZQ,MAVY,EAWZyC,cAXY,EAWI;AAChBrB,mBAZY,EAaZO,cAbY,EAcZE,eAdY,EAeZE,cAfY,EAgBZE,aAhBY,EAiBZE,gBAjBY,EAkBZE,gBAlBY,EAmBZmD,YAnBY,EAoBZ;AACAV,mBArBY,EAsBZrB,eAtBY,EAuBZI,iBAvBY,EAwBZ;AACA+C,mBAzBY,EAyBK;AACjBI,qBA1BY,EA0BO;AACnBI,qBA3BY,EA4BZI,mBA5BY,EA6BZ;AACAd,qBA9BY,EA8BO;AACnBI,uBA/BY,EA+BS;AACrBI,uBAhCY,EAiCZI,qBAjCY,EAkCZO,IAlCY,EAkCN;AACNE,OAnCY,EAoCZ;AACA;AACA;AACAzD,uBAvCY,EAwCZE,kBAxCY,EAyCZE,gBAzCY,EA0CZM,kBA1CY,EA2CZE,iBA3CY,EA4CZE,eA5CY,EA6CZ+C,MA7CY,EA8CZI,SA9CY,EA+CZE,iBA/CY,CADT;AAkDLM,oBAAgB,CAACd,OAAD,EAAUP,OAAV,EAAmBvE,YAAnB,EAAiCJ,QAAjC,EAA2CE,aAA3C,EAA0DkF,MAA1D,EAAkEI,SAAlE,EAA6EE,iBAA7E;AAlDX,GADiD;AAsDxDO,eAAa;AAtD2C,CAA1D;AAyDA,IAAMC,QAAQ,IAAI7L,WAAW+G,KAAf,CAAqByE,WAArB,CAAd;;AACO,IAAMM,WAAW,SAAXA,QAAW,CAAC/I,IAAD,EAA4C;AAClExC;AAEA,MAAIwL,YAAYF,MAAMC,QAAN,CAAe/I,IAAf,CAAhB;;AACA,MAAIgJ,UAAUC,MAAV,IAAoBD,UAAUC,MAAV,CAAiBlK,MAAjB,GAA0B,CAAlD,EAAqD;AACnD,UAAM,IAAImK,KAAJ,CAAU,sCAAV,CAAN;AACD,GANiE,CAQlE;;;AACA,MAAMjL,YAAYH,EAAEI,IAAF,CAAO8K,UAAUtL,MAAjB,CAAlB;;AACA,MAAIO,aAAad,aAAac,SAAb,EAAwBK,SAAxB,CAAjB,EAAqD;AACnD0K,cAAUtL,MAAV,CAAiB4B,GAAjB;AACD;;AAEDT,4BAA0BmK,UAAUtL,MAApC,EAA4CsL,UAAUrL,MAAtD;AAEA,SAAOqL,SAAP;AACD,CAjBM","sourcesContent":["\"use strict\";\n\nimport * as chevrotain from \"chevrotain\";\nimport * as _ from \"lodash\";\nimport { TokenNames } from \"./TokenNames\";\n\n\nconst createToken = chevrotain.createToken;\nconst createTokenInstance = chevrotain.createTokenInstance;\nconst tokenMatcher = chevrotain.tokenMatcher;\ntype groupsType = object;\n\n// State required for matching the indentations\nlet indentStack: number[] = [];\n// State required for matching bold and italic ranges in the right order\nlet rangesStack: string[] = [];\nexport const tokenList: chevrotain.TokenType[] = [];\nexport const NEWLINE_GROUP: string = \"NL_GROUP\";\n\nconst init = () => {\n  indentStack = [0];\n  rangesStack = [];\n};\nconst getCurrentLine = (tokens: chevrotain.IToken[], groups: any): number => {\n  const nlGroup = groups[NEWLINE_GROUP];\n  const matchedTokensIsEmpty = _.isEmpty(tokens);\n  const nlGroupIsEmpty = _.isEmpty(nlGroup);\n  if (matchedTokensIsEmpty && nlGroupIsEmpty) return 1;\n\n  const lastToken = _.last(tokens);\n  const lastNl: any = _.last(nlGroup);\n  let currentLine = lastToken ? lastToken.endLine! : 1;\n  if (lastToken && chevrotain.tokenMatcher(lastToken, Emptyline)) {\n    currentLine++;\n  }\n  if (lastNl && lastNl.endLine! + 1 > currentLine) {\n    currentLine = lastNl.endLine! + 1;\n  }\n  return currentLine;\n};\nconst getCurrentEndOffset = (tokens: chevrotain.IToken[], groups: any): number => {\n  const nlGroup = groups[NEWLINE_GROUP];\n  const matchedTokensIsEmpty = _.isEmpty(tokens);\n  const nlGroupIsEmpty = _.isEmpty(nlGroup);\n  if (matchedTokensIsEmpty && nlGroupIsEmpty) return 0;\n\n  const lastToken = _.last(tokens);\n  const lastNl: any = _.last(nlGroup);\n  const tokenEndOffset = lastToken ? lastToken.endOffset! : 0;\n  const nlEndOffset = lastNl ? lastNl.endOffset! : 0;\n  return tokenEndOffset > nlEndOffset ? tokenEndOffset : nlEndOffset;\n};\nconst lastTokenIsNewline = (lastToken: chevrotain.IToken | undefined, groups: any): boolean => {\n  const newlineGroup = groups[NEWLINE_GROUP];\n  const lastNl: any = _.last(newlineGroup);\n  return lastNl && (!lastToken || lastNl.endOffset! > lastToken.endOffset!);\n};\n\nconst emitRemainingDedentTokens = (\n  matchedTokens: chevrotain.IToken[],\n  groups: { [groupName: string]: chevrotain.IToken[] }\n): void => {\n  if (indentStack.length <= 1) {\n    return;\n  }\n  const lastToken = _.last(matchedTokens);\n  const startOffset = getCurrentEndOffset(matchedTokens, groups);\n  const endOffset = startOffset;\n  const startLine = getCurrentLine(matchedTokens, groups);\n  const endLine = startLine;\n  const startColumn = lastToken && lastToken.endColumn ? lastToken.endColumn : 0;\n  const endColumn = startColumn;\n\n  //add remaining Dedents\n  while (indentStack.length > 1) {\n    matchedTokens.push(\n      createTokenInstance(Dedent, \"\", startOffset, endOffset, startLine, endLine, startColumn, endColumn)\n    );\n    indentStack.pop();\n  }\n};\n\nconst emitIndentOrDedent = (\n  matchedTokens: chevrotain.IToken[],\n  groups: { [groupName: string]: chevrotain.IToken[] },\n  indentStr: string\n): void => {\n  const currIndentLevel = indentStr.length;\n  let lastIndentLevel = _.last(indentStack) || 0;\n  const image = \"\";\n  const startOffset = getCurrentEndOffset(matchedTokens, groups) + 1;\n  const endOffset = startOffset + indentStr.length - 1;\n  const startLine = getCurrentLine(matchedTokens, groups);\n  const endLine = startLine;\n  const startColumn = 1;\n  const endColumn = startColumn + indentStr.length - 1;\n  if (currIndentLevel > lastIndentLevel) {\n    indentStack.push(currIndentLevel);\n    let indentToken = createTokenInstance(\n      Indent,\n      image,\n      startOffset,\n      endOffset,\n      startLine,\n      endLine,\n      startColumn,\n      endColumn\n    );\n    matchedTokens.push(indentToken);\n  } else if (currIndentLevel < lastIndentLevel) {\n    while (indentStack.length > 1 && currIndentLevel < lastIndentLevel) {\n      indentStack.pop();\n      lastIndentLevel = _.last(indentStack) || 0;\n      let dedentToken = createTokenInstance(\n        Dedent,\n        image,\n        startOffset,\n        endOffset,\n        startLine,\n        endLine,\n        startColumn,\n        endColumn\n      );\n      matchedTokens.push(dedentToken);\n    }\n  }\n};\nconst matchRelation = (\n  text: string,\n  offset?: number,\n  tokens?: chevrotain.IToken[],\n  groups?: object,\n  pattern?: RegExp\n) => {\n  const remainingText = text.substr(offset || 0);\n  const lastToken = _.last(tokens);\n  const afterNewline = lastTokenIsNewline(lastToken, groups!);\n  const afterEmptyline = lastToken && tokenMatcher(lastToken, Emptyline);\n\n  if (_.isEmpty(tokens) || afterEmptyline || afterNewline) {\n    //relations after Emptyline are illegal, but we need the token for error reporting\n    let match = pattern!.exec(remainingText);\n    if (match !== null && match.length == 3) {\n      const indentStr = match[1];\n      emitIndentOrDedent(tokens!, <any>groups!, indentStr);\n      return match;\n    }\n  }\n  return null;\n};\n//relations start at BOF or after a newline, optionally followed by indentation (spaces or tabs)\nconst matchIncomingSupport = _.partialRight(matchRelation, /^([' '\\t]*)(\\+>)/);\nconst matchIncomingAttack = _.partialRight(matchRelation, /^([' '\\t]*)(->)/);\nconst matchOutgoingSupport = _.partialRight(matchRelation, /^([' '\\t]*)(<?\\+)/);\nconst matchOutgoingAttack = _.partialRight(matchRelation, /^([' '\\t]*)(<?-)/);\nconst matchContradiction = _.partialRight(matchRelation, /^([' '\\t]*)(><)/);\nconst matchIncomingUndercut = _.partialRight(matchRelation, /^([' '\\t]*)(_>)/);\nconst matchOutgoingUndercut = _.partialRight(matchRelation, /^([' '\\t]*)(<_)/);\n\nexport const IncomingSupport = createToken({\n  name: TokenNames.INCOMING_SUPPORT,\n  pattern: matchIncomingSupport,\n  line_breaks: true,\n  label: \"+> (Incoming Support)\",\n  start_chars_hint: [\" \", \"\\t\", \"+\"]\n});\ntokenList.push(IncomingSupport);\n\nexport const IncomingAttack = createToken({\n  name: TokenNames.INCOMING_ATTACK,\n  pattern: matchIncomingAttack,\n  line_breaks: true,\n  label: \"-> (Incoming Attack)\",\n  start_chars_hint: [\" \", \"\\t\", \"-\"]\n});\ntokenList.push(IncomingAttack);\n\nexport const OutgoingSupport = createToken({\n  name: TokenNames.OUTGOING_SUPPORT,\n  pattern: matchOutgoingSupport,\n  line_breaks: true,\n  label: \"<+ (Outgoing Support)\",\n  start_chars_hint: [\" \", \"\\t\", \"<\"]\n});\ntokenList.push(OutgoingSupport);\n\nexport const OutgoingAttack = createToken({\n  name: TokenNames.OUTGOING_ATTACK,\n  pattern: matchOutgoingAttack,\n  line_breaks: true,\n  label: \"<- (Outgoing Attack)\",\n  start_chars_hint: [\" \", \"\\t\", \"<\"]\n});\ntokenList.push(OutgoingAttack);\n\nexport const Contradiction = createToken({\n  name: TokenNames.CONTRADICTION,\n  pattern: matchContradiction,\n  line_breaks: true,\n  label: \">< (Contradiction)\",\n  start_chars_hint: [\" \", \"\\t\", \">\"]\n});\ntokenList.push(Contradiction);\nexport const IncomingUndercut = createToken({\n  name: TokenNames.INCOMING_UNDERCUT,\n  pattern: matchIncomingUndercut,\n  line_breaks: true,\n  label: \"_> (Incoming Undercut)\",\n  start_chars_hint: [\" \", \"\\t\", \"_\"]\n});\ntokenList.push(IncomingUndercut);\nexport const OutgoingUndercut = createToken({\n  name: TokenNames.OUTGOING_UNDERCUT,\n  pattern: matchOutgoingUndercut,\n  line_breaks: true,\n  label: \"<_ (Outgoing Undercut)\",\n  start_chars_hint: [\" \", \"\\t\", \"<\"]\n});\ntokenList.push(OutgoingUndercut);\n\nconst inferenceStartPattern = /^[' '\\t]*-{2}/;\n\nconst matchInferenceStart: chevrotain.CustomPatternMatcherFunc = (text, offset, tokens, groups) => {\n  let remainingText = text.substr(offset || 0);\n  const lastToken = _.last(tokens);\n  let afterNewline = lastTokenIsNewline(lastToken, groups!);\n  if (_.isEmpty(tokens) || afterNewline) {\n    const match = inferenceStartPattern.exec(remainingText);\n    if (match != null) {\n      emitRemainingDedentTokens(tokens!, <any>groups!);\n      return match;\n    }\n  }\n  return null;\n};\n\nexport const InferenceStart = createToken({\n  name: TokenNames.INFERENCE_START,\n  pattern: matchInferenceStart,\n  push_mode: \"inference_mode\",\n  line_breaks: true,\n  label: \"-- (Inference Start)\",\n  start_chars_hint: [\" \", \"\\t\", \"-\"]\n});\ntokenList.push(InferenceStart);\n\nexport const FrontMatter = createToken({\n  name: TokenNames.FRONT_MATTER,\n  pattern: /===[^=]*===/,\n  label: \"Front Matter (YAML)\"\n});\ntokenList.push(FrontMatter);\n\nconst metaDataPattern = /{((?!}\\s[^\\,}])(.|\\n))*}(?!\\s*(\\,|}))/;\n// const metaDataOpeningBracketPattern = /^[^}]*?{/;\n// const metaDataClosingBracketPattern = /^[^{]*?}/;\n// const matchMetaData: chevrotain.CustomPatternMatcherFunc = (text, offset, tokens, groups) => {\n//   if (text.charAt(offset) !== \"{\" && text.length >= offset + 1) {\n//     return null;\n//   }\n//   let remainingText = text.substr(offset + 1);\n//   let result = \"{\";\n//   let nrOfOpenBrackets = 1;\n\n//   while (nrOfOpenBrackets > 0 && remainingText.length > 0) {\n//     const nextOpeningBracket = metaDataOpeningBracketPattern.exec(remainingText);\n//     if (nextOpeningBracket) {\n//       result += remainingText.substr(0, nextOpeningBracket[0].length);\n//       remainingText = remainingText.substr(nextOpeningBracket[0].length);\n//       nrOfOpenBrackets++;\n//     } else {\n//       const nextClosingBracket = metaDataClosingBracketPattern.exec(remainingText);\n//       if (nextClosingBracket) {\n//         result += remainingText.substr(0, nextClosingBracket[0].length);\n//         remainingText = remainingText.substr(nextClosingBracket[0].length);\n//         nrOfOpenBrackets--;\n//       } else {\n//         return null;\n//       }\n//     }\n//   }\n//   if (nrOfOpenBrackets > 0) {\n//     return null;\n//   }\n//   let match: any = [result];\n//   match.index = 0;\n//   let rArray = <RegExpExecArray>match;\n//   return rArray;\n// };\nexport const MetaData = createToken({\n  name: TokenNames.META_DATA,\n  pattern: /{((?!}\\s[^\\,}])(.|\\n))*}(?!\\s*(\\,|}))/,\n  label: \"Meta Data (YAML)\"\n});\ntokenList.push(MetaData);\nexport const ListDelimiter = createToken({\n  name: TokenNames.LIST_DELIMITER,\n  pattern: /,/,\n  label: \",\"\n});\ntokenList.push(ListDelimiter);\n// export const Colon = createToken({\n//   name: \"Colon\",\n//   pattern: /:/,\n//   label: \":\"\n// });\n// tokens.push(Colon);\n\n// export const MetadataStatementEnd = createToken({\n//   name: \"MetadataStatementEnd\",\n//   pattern: /;/,\n//   label: \";\"\n// });\n// tokens.push(MetadataStatementEnd);\n// export const MetadataStart = createToken({\n//   name: \"MetadataStart\",\n//   pattern: /\\(/,\n//   label: \"(\"\n// });\n// tokens.push(MetadataStart);\n// export const MetadataEnd = createToken({\n//   name: \"MetadataEnd\",\n//   pattern: /\\)/,\n//   label: \")\"\n// });\n// tokens.push(MetadataEnd);\n\nexport const InferenceEnd = createToken({\n  name: TokenNames.INFERENCE_END,\n  pattern: /-{2,}/,\n  pop_mode: true,\n  label: \"-- (Inference End)\"\n});\ntokenList.push(InferenceEnd);\n\nconst matchListItem = (\n  text: string,\n  offset?: number,\n  tokens?: chevrotain.IToken[],\n  groups?: { [groupName: string]: chevrotain.IToken[] },\n  pattern?: RegExp\n): RegExpExecArray | null => {\n  let remainingText = text.substr(offset || 0);\n  let last = _.last(tokens);\n  let afterNewline = lastTokenIsNewline(last, groups!);\n  let afterEmptyline = last && tokenMatcher(last, Emptyline);\n  if (_.isEmpty(tokens) || afterEmptyline || afterNewline) {\n    let match = pattern!.exec(remainingText);\n    if (match !== null) {\n      const indentStr = match[1];\n      emitIndentOrDedent(tokens!, groups!, indentStr);\n      return match;\n    }\n  }\n  return null;\n};\n\nconst orderedListItemPattern = /^([' '\\t]+)\\d+\\.(?=\\s)/;\nconst matchOrderedListItem = _.partialRight(matchListItem, orderedListItemPattern);\n\nexport const OrderedListItem = createToken({\n  name: TokenNames.ORDERED_LIST_ITEM,\n  pattern: matchOrderedListItem,\n  line_breaks: true,\n  label: \"{Indentation}{number}. (Ordered List Item)\",\n  start_chars_hint: [\" \", \"\\t\"]\n});\ntokenList.push(OrderedListItem);\n//whitespace + * + whitespace (to distinguish list items from bold and italic ranges)\nconst unorderedListItemPattern = /^([' '\\t]+)\\*(?=\\s)/;\nconst matchUnorderedListItem = _.partialRight(matchListItem, unorderedListItemPattern);\n\nexport const UnorderedListItem = createToken({\n  name: TokenNames.UNORDERED_LIST_ITEM,\n  pattern: matchUnorderedListItem,\n  line_breaks: true,\n  label: \"{Indentation}* (Unordered List Item)\",\n  start_chars_hint: [\" \", \"\\t\"]\n});\ntokenList.push(UnorderedListItem);\n\n//This does not work with \\r\\n|\\n||r as a simple CRLF linebreak will be interpreted as an Emptyline\n//Instead we drop the last alternative (\\r?\\n would work as well)\nconst emptylinePattern = /^((?:\\r\\n|\\n)[ \\t]*(?:\\r\\n|\\n)+)/; //two or more linebreaks\nconst matchEmptyline = (text: string, offset?: number, tokens?: chevrotain.IToken[], groups?: object) => {\n  let remainingText = text.substr(offset || 0);\n  let last = _.last(tokens);\n  //ignore Emptylines after first one (relevant for Emptylines after ignored comments)\n  if (last && tokenMatcher(last, Emptyline)) return null;\n  let match = emptylinePattern.exec(remainingText);\n  if (match !== null && match[0].length < remainingText.length) {\n    //ignore trailing linebreaks\n    emitRemainingDedentTokens(tokens!, <any>groups!);\n    //TODO: emitRemainingRanges (to be more resistant against unclosed bold and italic ranges)\n    return match;\n  }\n  return null;\n};\nexport const Emptyline = createToken({\n  name: TokenNames.EMPTYLINE,\n  pattern: matchEmptyline,\n  line_breaks: true,\n  label: \"{linebreak}{linebreak} (Empty Line)\",\n  start_chars_hint: [\"\\r\", \"\\n\"]\n});\ntokenList.push(Emptyline);\n\n//Indent and Dedent are never matched with their own patterns, instead they get matched in the relations custom patterns\nexport const Indent = createToken({\n  name: TokenNames.INDENT,\n  pattern: chevrotain.Lexer.NA\n});\ntokenList.push(Indent);\n\nexport const Dedent = createToken({\n  name: TokenNames.DEDENT,\n  pattern: chevrotain.Lexer.NA\n});\ntokenList.push(Dedent);\n\nexport const StatementDefinition = createToken({\n  name: TokenNames.STATEMENT_DEFINITION,\n  pattern: /\\[.+?\\]\\:/,\n  label: \"[Statement Title]: (Statement Definition)\"\n});\ntokenList.push(StatementDefinition);\n\n// $.StatementDefinitionByNumber = createToken({\n//     name: \"StatementDefinitionByNumber\",\n//     pattern: /\\<(.+?)\\>\\((\\d+)\\)\\:/\n// });\n// $.tokens.push($.StatementDefinitionByNumber);\n\nexport const StatementReference = createToken({\n  name: TokenNames.STATEMENT_REFERENCE,\n  pattern: /\\[.+?\\]/,\n  label: \"[Statement Title] (Statement Reference)\"\n});\ntokenList.push(StatementReference);\n\n// $.StatementReferenceByNumber = createToken({\n//     name: \"StatementReferenceByNumber\",\n//     pattern: /\\<(.+?)\\>\\(\\d+\\)/\n// });\n// $.tokens.push($.StatementReferenceByNumber);\n\nexport const StatementMention = createToken({\n  name: TokenNames.STATEMENT_MENTION,\n  pattern: /\\@\\[.+?\\][ \\t]?/,\n  label: \"@[Statement Title] (Statement Mention)\"\n});\ntokenList.push(StatementMention);\n\n// $.StatementMentionByNumber = createToken({\n//     name: \"StatementMentionByNumber\",\n//     pattern: /\\@\\<(.+?)\\>\\(\\d+\\)/\n// });\n// $.tokens.push($.StatementMentionByNumber);\n\nconst statementNumberPattern = /^[' '\\t]*\\(\\d+\\)/;\nconst matchStatementNumber = (text: string, offset?: number, tokens?: chevrotain.IToken[], groups?: object) => {\n  let remainingText = text.substr(offset || 0);\n  var last = _.last(tokens);\n  let afterNewline = lastTokenIsNewline(last, groups!);\n  let afterEmptyline = last && tokenMatcher(last, Emptyline);\n\n  //Statement in argument reconstruction:\n  if (_.isEmpty(tokens) || afterEmptyline || afterNewline) {\n    let match = statementNumberPattern.exec(remainingText);\n    if (match !== null) {\n      emitRemainingDedentTokens(tokens!, <any>groups!);\n      return match;\n    }\n  }\n  return null;\n};\nexport const StatementNumber = createToken({\n  name: TokenNames.STATEMENT_NUMBER,\n  pattern: matchStatementNumber,\n  line_breaks: true,\n  label: \"(Number) (Statement Number)\",\n  start_chars_hint: [\" \", \"\\t\", \"(\"]\n});\ntokenList.push(StatementNumber);\n\nexport const ArgumentDefinition = createToken({\n  name: TokenNames.ARGUMENT_DEFINITION,\n  pattern: /\\<.+?\\>\\:/,\n  label: \"<Argument Title>: (Argument Definition)\"\n});\ntokenList.push(ArgumentDefinition);\n\nexport const ArgumentReference = createToken({\n  name: TokenNames.ARGUMENT_REFERENCE,\n  pattern: /\\<.+?\\>/,\n  label: \"<Argument Title> (Argument Reference)\"\n});\ntokenList.push(ArgumentReference);\n\nexport const ArgumentMention = createToken({\n  name: TokenNames.ARGUMENT_MENTION,\n  pattern: /\\@\\<.+?\\>[ \\t]?/,\n  label: \"@<Argument Title> (Argument Mention)\"\n});\ntokenList.push(ArgumentMention);\n\nconst headingPattern = /^(#+)(?: )/;\nconst matchHeadingStart = (text: string, offset?: number, tokens?: chevrotain.IToken[], groups?: object) => {\n  let remainingText = text.substr(offset || 0);\n  let last = _.last(tokens);\n  let afterEmptyline = last && tokenMatcher(last, Emptyline);\n\n  if (!last || afterEmptyline) {\n    const match = headingPattern.exec(remainingText);\n    if (match) {\n      return match;\n    }\n  }\n  return null;\n};\nexport const HeadingStart = createToken({\n  name: TokenNames.HEADING_START,\n  pattern: matchHeadingStart,\n  label: \"# (Heading Start)\",\n  start_chars_hint: [\"#\"]\n});\ntokenList.push(HeadingStart);\n\n//BOLD and ITALIC ranges\nconst matchBoldOrItalicStart = (\n  text: string,\n  offset?: number,\n  tokens?: chevrotain.IToken[],\n  groups?: object,\n  pattern?: RegExp,\n  rangeType?: string\n) => {\n  let remainingText = text.substr(offset || 0);\n  let match = pattern!.exec(remainingText);\n  if (match != null) {\n    rangesStack.push(rangeType!);\n    return match;\n  }\n  return null;\n};\n\nconst matchBoldOrItalicEnd = (\n  text: string,\n  offset?: number,\n  tokens?: chevrotain.IToken[],\n  groups?: any,\n  pattern?: RegExp,\n  rangeType?: string\n): RegExpExecArray | null => {\n  let lastRange = _.last(rangesStack);\n  if (lastRange != rangeType) return null;\n  //first check if the last match was skipped Whitespace\n  let skipped: any = groups ? groups[chevrotain.Lexer.SKIPPED] : null;\n  let lastSkipped: any = _.last(skipped);\n  let lastMatched = _.last(tokens);\n  if (!lastMatched || (lastSkipped && lastSkipped.endOffset! > lastMatched.endOffset!)) {\n    return null;\n  }\n  let remainingText = text.substr(offset || 0);\n  let match = pattern!.exec(remainingText);\n\n  if (match != null) {\n    rangesStack.pop();\n    return match;\n  }\n  return null;\n};\nconst matchAsteriskBoldStart = _.partialRight(matchBoldOrItalicStart, /^\\*\\*(?!\\s)/, \"AsteriskBold\");\nconst matchAsteriskBoldEnd = _.partialRight(\n  matchBoldOrItalicEnd,\n  /^\\*\\*(?:[ \\t]|(?=\\n|\\r|\\)|\\}|\\_|\\.|,|!|\\?|;|:|-|\\*|$))/,\n  \"AsteriskBold\"\n);\n\nconst matchUnderscoreBoldStart = _.partialRight(matchBoldOrItalicStart, /^__(?!\\s)/, \"UnderscoreBold\");\nconst matchUnderscoreBoldEnd = _.partialRight(\n  matchBoldOrItalicEnd,\n  /^__(?:[ \\t]|(?=\\n|\\r|\\)|\\}|\\_|\\.|,|!|\\?|;|:|-|\\*|$))/,\n  \"UnderscoreBold\"\n);\n\nconst matchAsteriskItalicStart = _.partialRight(matchBoldOrItalicStart, /^\\*(?!\\s)/, \"AsteriskItalic\");\nconst matchAsteriskItalicEnd = _.partialRight(\n  matchBoldOrItalicEnd,\n  /^\\*(?:[ \\t]|(?=\\n|\\r|\\)|\\}|\\_|\\.|,|!|\\?|;|:|-|\\*|$))/,\n  \"AsteriskItalic\"\n);\n\nconst matchUnderscoreItalicStart = _.partialRight(matchBoldOrItalicStart, /^\\_(?!\\s)/, \"UnderscoreItalic\");\nconst matchUnderscoreItalicEnd = _.partialRight(\n  matchBoldOrItalicEnd,\n  /^\\_(?:[ \\t]|(?=\\n|\\r|\\)|\\}|\\_|\\.|,|!|\\?|;|:|-|\\*|$))/,\n  \"UnderscoreItalic\"\n);\n\nexport const AsteriskBoldStart = createToken({\n  name: TokenNames.ASTERISK_BOLD_START,\n  pattern: matchAsteriskBoldStart,\n  label: \"** (Bold Start)\",\n  start_chars_hint: [\"*\"]\n});\ntokenList.push(AsteriskBoldStart);\n\nexport const AsteriskBoldEnd = createToken({\n  name: TokenNames.ASTERISK_BOLD_END,\n  pattern: matchAsteriskBoldEnd,\n  label: \"** (Bold End)\",\n  start_chars_hint: [\"*\"]\n});\ntokenList.push(AsteriskBoldEnd);\n\nexport const UnderscoreBoldStart = createToken({\n         name: TokenNames.UNDERSCORE_BOLD_START,\n         pattern: matchUnderscoreBoldStart,\n         label: \"__ (Bold Start)\",\n         start_chars_hint: [\"_\"]\n       });\ntokenList.push(UnderscoreBoldStart);\n\nexport const UnderscoreBoldEnd = createToken({\n         name: TokenNames.UNDERSCORE_BOLD_END,\n         pattern: matchUnderscoreBoldEnd,\n         label: \"__ (Bold End)\",\n         start_chars_hint: [\"_\"]\n       });\ntokenList.push(UnderscoreBoldEnd);\n\nexport const AsteriskItalicStart = createToken({\n         name: TokenNames.ASTERISK_ITALIC_START,\n         pattern: matchAsteriskItalicStart,\n         label: \"* (Italic Start)\",\n         start_chars_hint: [\"*\"]\n       });\ntokenList.push(AsteriskItalicStart);\n\nexport const AsteriskItalicEnd = createToken({\n  name: TokenNames.ASTERISK_ITALIC_END,\n  pattern: matchAsteriskItalicEnd,\n  label: \"* (Italic End)\",\n  start_chars_hint: [\"*\"]\n});\ntokenList.push(AsteriskItalicEnd);\n\nexport const UnderscoreItalicStart = createToken({\n  name: TokenNames.UNDERSCORE_ITALIC_START,\n  pattern: matchUnderscoreItalicStart,\n  label: \"_ (Italic Start)\",\n  start_chars_hint: [\"_\"]\n});\ntokenList.push(UnderscoreItalicStart);\n\nexport const UnderscoreItalicEnd = createToken({\n  name: TokenNames.UNDERSCORE_ITALIC_END,\n  pattern: matchUnderscoreItalicEnd,\n  label: \"_ (Italic End)\",\n  start_chars_hint: [\"_\"]\n});\ntokenList.push(UnderscoreItalicEnd);\n\nexport const Comment = createToken({\n  name: TokenNames.COMMENT,\n  pattern: /(?:<!--(?:.|\\n|\\r)*?-->)|(?:\\/\\*(?:.|\\n|\\r)*?\\*\\/)|(?:\\/\\/.*?(?=\\r\\n|\\n|\\r))/,\n  group: chevrotain.Lexer.SKIPPED,\n  line_breaks: true,\n  label: \"// or /**/ or <!-- --> (Comment)\"\n});\ntokenList.push(Comment);\n\nexport const Link = createToken({\n  name: TokenNames.LINK,\n  pattern: /\\[[^\\]]+?\\]\\([^\\)]+?\\)[ \\t]?/,\n  label: \"[Title](Url) (Link)\"\n});\ntokenList.push(Link);\n\nexport const Tag = createToken({\n  name: TokenNames.TAG,\n  pattern: /#(?:\\([^\\)]+\\)|[a-zA-z0-9-\\u00A0-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF]+)[ \\t]?/,\n  label: \"#tag-text or #(tag text) (Tag)\"\n});\ntokenList.push(Tag);\n\nexport const Newline = createToken({\n  name: TokenNames.NEWLINE,\n  pattern: /(?:\\r\\n|\\n|\\r)/,\n  group: \"NL_GROUP\",\n  line_breaks: true,\n  label: \"{linebreak} (New Line)\"\n});\ntokenList.push(Newline);\n\nexport const Spaces = createToken({\n  name: TokenNames.SPACES,\n  pattern: /( |\\t)+/,\n  group: chevrotain.Lexer.SKIPPED\n});\ntokenList.push(Spaces);\n\nexport const EscapedChar = createToken({\n  name: TokenNames.ESCAPED_CHAR,\n  pattern: /\\\\.(?: )*/,\n  label: \"\\\\{character} (Escaped Character)\"\n});\ntokenList.push(EscapedChar);\n\n//The rest of the text that is free of any Argdown syntax\nexport const Freestyle = createToken({\n  name: TokenNames.FREESTYLE,\n  pattern: /[^\\\\\\@\\#\\*\\_\\[\\]\\,\\:\\;\\<\\/\\>\\-\\r\\n\\(\\)\\{\\}]+/,\n  line_breaks: true,\n  label: \"Text Content\"\n});\ntokenList.push(Freestyle);\n\n//Freestyle text needs to be \"cut up\" by these control characters so that the other rules get a chance to succeed.\n//Otherwise, every line would simply be lexed as a single Freestyle token.\n//If these chars are not consumed by other rules, they are lexed as \"useless\" UnusedControlChars. The parser then has to combine Freestyle and UnusedControlChar tokens back together to get \"normal text\" token sequences.\n//Note that some \"meaningful\" characters (like +) are not listed here, as they are only meaningful after a linebreak and freestyle text already gets \"cut up\" by each line break.\nexport const UnusedControlChar = createToken({\n  name: TokenNames.UNUSED_CONTROL_CHAR,\n  pattern: /[\\@\\#\\*\\_\\[\\]\\,\\:\\;\\<\\/\\>\\-\\(\\)\\{\\}][ \\t]?/,\n  label: \"Text Content (Special Characters)\"\n});\ntokenList.push(UnusedControlChar);\n\nexport const EOF = chevrotain.EOF;\n\nconst lexerConfig: chevrotain.IMultiModeLexerDefinition = {\n  modes: {\n    default_mode: [\n      Comment,\n      FrontMatter,\n      MetaData,\n      EscapedChar, //must come first after $.Comment\n      Emptyline,\n      Newline,\n      // Relation tokens must appear before Spaces, otherwise all indentation will always be consumed as spaces.\n      // Dedent must appear before Indent for handling zero spaces dedents.\n      Dedent,\n      Indent,\n      InferenceStart, //needs to be lexed before OutgoingAttack (- vs --)\n      IncomingSupport,\n      IncomingAttack,\n      OutgoingSupport,\n      OutgoingAttack,\n      Contradiction,\n      IncomingUndercut,\n      OutgoingUndercut,\n      HeadingStart,\n      //$.ArgumentStatementStart,\n      StatementNumber,\n      OrderedListItem,\n      UnorderedListItem,\n      //The ends of Bold and italic ranges need to be lexed before the starts\n      AsteriskBoldEnd, //BoldEnd needs to be lexed before ItalicEnd (** vs *)\n      UnderscoreBoldEnd, //BoldEnd needs to be lexed before ItalicEnd (__ vs _)\n      AsteriskItalicEnd,\n      UnderscoreItalicEnd,\n      //The starts of Bold and italic ranges need to be lexed after the ends\n      AsteriskBoldStart, //BoldStart needs to be lexed before ItalicStart (** vs *)\n      UnderscoreBoldStart, //BoldStart needs to be lexed before ItalicStart (__ vs _)\n      AsteriskItalicStart,\n      UnderscoreItalicStart,\n      Link, //needs to be lexed before StatementReference\n      Tag,\n      // $.StatementDefinitionByNumber, // needs to be lexed before ArgumentReference\n      // $.StatementReferenceByNumber, // needs to be lexed before ArgumentReference\n      // $.StatementMentionByNumber, // needs to be lexed before ArgumentReference\n      StatementDefinition,\n      StatementReference,\n      StatementMention,\n      ArgumentDefinition,\n      ArgumentReference,\n      ArgumentMention,\n      Spaces,\n      Freestyle,\n      UnusedControlChar\n    ],\n    inference_mode: [Newline, Comment, InferenceEnd, MetaData, ListDelimiter, Spaces, Freestyle, UnusedControlChar]\n  },\n\n  defaultMode: \"default_mode\"\n};\n\nconst lexer = new chevrotain.Lexer(lexerConfig);\nexport const tokenize = (text: string): chevrotain.ILexingResult => {\n  init();\n\n  let lexResult = lexer.tokenize(text);\n  if (lexResult.errors && lexResult.errors.length > 0) {\n    throw new Error(\"sad sad panda lexing errors detected\");\n  }\n\n  //remove trailing Emptyline (parser cannot cope with it)\n  const lastToken = _.last(lexResult.tokens);\n  if (lastToken && tokenMatcher(lastToken, Emptyline)) {\n    lexResult.tokens.pop();\n  }\n\n  emitRemainingDedentTokens(lexResult.tokens, lexResult.groups);\n\n  return lexResult;\n};\n"],"file":"lexer.js"}