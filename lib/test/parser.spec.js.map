{"version":3,"sources":["../../test/parser.spec.js"],"names":["lexer","parser","walker","describe","it","source","readFileSync","lexResult","tokenize","input","tokens","parseResult","argdown","errors","to","be","empty","statements","on","node","name","equal","walk"],"mappings":";;AACA;;AACA;;;;AACA;;;;AAEA,IAAMA,2BAAN,C,CALA;;AAMA,IAAMC,6BAAN;AACA,IAAMC,SAAS,8BAAf;;AAEAC,SAAS,QAAT,EAAmB,YAAW;AAC1BC,KAAG,gCAAH,EAAqC,YAAU;AAC/C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAIC,YAAYP,MAAMQ,QAAN,CAAeH,MAAf,CAAhB;AACAJ,WAAOQ,KAAP,GAAeF,UAAUG,MAAzB;AACA,QAAIC,cAAcV,OAAOW,OAAP,EAAlB;AACA;AACA;AACA;AACA,sBAAOL,UAAUM,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOf,OAAOY,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAVC;AAWFZ,KAAG,+CAAH,EAAoD,YAAU;AAC5D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,iCAAhB,EAAmD,MAAnD,CAAb;AACA,QAAIC,YAAYP,MAAMQ,QAAN,CAAeH,MAAf,CAAhB;AACAJ,WAAOQ,KAAP,GAAeF,UAAUG,MAAzB;AACA,QAAIC,cAAcV,OAAOW,OAAP,EAAlB;AACA,sBAAOL,UAAUM,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOf,OAAOY,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAPD;AAQD,CApBD;;AAsBAb,SAAS,mBAAT,EAA8B,YAAW;AACvCC,KAAG,UAAH,EAAe,YAAU;AACvB,QAAIC,SAAS,aAAb;AACA,QAAIE,YAAYP,MAAMQ,QAAN,CAAeH,MAAf,CAAhB;AACAJ,WAAOQ,KAAP,GAAeF,UAAUG,MAAzB;AACA,QAAIC,cAAcV,OAAOW,OAAP,EAAlB;AACA,QAAIK,aAAa,CAAjB;AACAf,WAAOgB,EAAP,CAAU,gBAAV,EAA2B,UAACC,IAAD,EAAQ;AAACF,mBAAc,kBAAOE,KAAKC,IAAZ,EAAkBN,EAAlB,CAAqBO,KAArB,CAA2B,WAA3B;AAAyC,KAA3F;AACAnB,WAAOoB,IAAP,CAAYX,WAAZ;AACA,sBAAOM,UAAP,EAAmBH,EAAnB,CAAsBO,KAAtB,CAA4B,CAA5B;AACD,GATD;AAUD,CAXD","file":"parser.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from 'chai';\nimport fs from 'fs';\nimport {ArgdownLexer, ArgdownParser, ArgdownTreeWalker} from '../src/index.js';\n\nconst lexer = ArgdownLexer;\nconst parser = ArgdownParser;\nconst walker = new ArgdownTreeWalker();\n\ndescribe(\"Parser\", function() {\n    it(\"can parse complex argdown file\", function(){\n    let source = fs.readFileSync(\"./test/veggie_debate.argdown\", 'utf8');\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    let parseResult = parser.argdown();\n    //parser.logAst(parseResult);\n    //console.log(parser.errors);\n    //lexer.logTokens(lexResult.tokens);\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n  it(\"can parse argument definitions and references\", function(){\n    let source = fs.readFileSync(\"./test/parser-arguments.argdown\", 'utf8');\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    let parseResult = parser.argdown();\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n});\n\ndescribe(\"ArgdownTreeWalker\", function() {\n  it(\"can walk\", function(){\n    let source = \"Hallo Welt!\";\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    let parseResult = parser.argdown();\n    let statements = 0;\n    walker.on('statementEntry',(node)=>{statements++; expect(node.name).to.equal('statement');});\n    walker.walk(parseResult);\n    expect(statements).to.equal(1);\n  });\n});\n"]}