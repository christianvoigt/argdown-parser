{"version":3,"sources":["../../test/parser.spec.js"],"names":["lexer","parser","walker","describe","it","source","lexResult","tokenize","input","tokens","argdown","errors","to","be","empty","readFileSync","exist","ast","statements","on","request","response","node","name","equal","walk"],"mappings":";;AACA;;AACA;;;;AACA;;;;AAEA,IAAMA,2BAAN,C,CALA;;AAMA,IAAMC,6BAAN;AACA,IAAMC,SAAS,8BAAf;;AAEAC,SAAS,QAAT,EAAmB,YAAW;AAC5BC,KAAG,wDAAH,EAA6D,YAAU;AACrE,QAAIC,SAAS,kDAAb;AACA,QAAIC,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACAR,WAAOS,OAAP;AACA,sBAAOJ,UAAUK,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOb,OAAOU,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAPD;AAQAV,KAAG,gCAAH,EAAqC,YAAU;AAC7C,QAAIC,SAAS,aAAGU,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAIT,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACAR,WAAOS,OAAP;AACA,sBAAOJ,UAAUK,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOb,OAAOU,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAPD;AAQAV,KAAG,+CAAH,EAAoD,YAAU;AAC5D,QAAIC,SAAS,aAAGU,YAAH,CAAgB,iCAAhB,EAAmD,MAAnD,CAAb;AACA,QAAIT,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACAR,WAAOS,OAAP;AACA,sBAAOJ,UAAUK,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOb,OAAOU,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAPD;AAQAV,KAAG,mBAAH,EAAwB,YAAU;AAChC,QAAIC,SAAS,yBAAb;AACA,QAAIC,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACAR,WAAOS,OAAP;AACA;AACA,sBAAOJ,UAAUK,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOb,OAAOU,MAAd,EAAsBC,EAAtB,CAAyBI,KAAzB;AACD,GARD;AASAZ,KAAG,uBAAH,EAA4B,YAAY;AACtC,QAAIC,SAAS,0BAAb;AACA,QAAIC,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACAR,WAAOS,OAAP;AACA,sBAAOJ,UAAUK,MAAjB,EAAyBC,EAAzB,CAA4BC,EAA5B,CAA+BC,KAA/B;AACA,sBAAOb,OAAOU,MAAd,EAAsBC,EAAtB,CAAyBC,EAAzB,CAA4BC,KAA5B;AACD,GAPD;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACD,CAlDD;;AAoDAX,SAAS,mBAAT,EAA8B,YAAW;AACvCC,KAAG,UAAH,EAAe,YAAU;AACvB,QAAIC,SAAS,aAAb;AACA,QAAIC,YAAYN,MAAMO,QAAN,CAAeF,MAAf,CAAhB;AACAJ,WAAOO,KAAP,GAAeF,UAAUG,MAAzB;AACA,QAAIQ,MAAMhB,OAAOS,OAAP,EAAV;AACA,QAAIQ,aAAa,CAAjB;AACAhB,WAAOiB,EAAP,CAAU,gBAAV,EAA2B,UAACC,OAAD,EAAUC,QAAV,EAAoBC,IAApB,EAA2B;AAACJ,mBAAc,kBAAOI,KAAKC,IAAZ,EAAkBX,EAAlB,CAAqBY,KAArB,CAA2B,WAA3B;AAAyC,KAA9G;AACAtB,WAAOuB,IAAP,CAAY,EAAZ,EAAgB,EAACR,KAAKA,GAAN,EAAhB;AACA,sBAAOC,UAAP,EAAmBN,EAAnB,CAAsBY,KAAtB,CAA4B,CAA5B;AACD,GATD;AAUD,CAXD","file":"parser.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from 'chai';\nimport fs from 'fs';\nimport {ArgdownLexer, ArgdownParser, ArgdownTreeWalker} from '../src/index.js';\n\nconst lexer = ArgdownLexer;\nconst parser = ArgdownParser;\nconst walker = new ArgdownTreeWalker();\n\ndescribe(\"Parser\", function() {\n  it(\"can parse argdown with leading and trailing emptylines\", function(){\n    let source = \"\\n\\n\\n\\n\\nHallo World!\\n\\n\\n<!-- Comment -->\\n\\n\";\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    parser.argdown();\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n  it(\"can parse complex argdown file\", function(){\n    let source = fs.readFileSync(\"./test/veggie_debate.argdown\", 'utf8');\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    parser.argdown();\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n  it(\"can parse argument definitions and references\", function(){\n    let source = fs.readFileSync(\"./test/parser-arguments.argdown\", 'utf8');\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    parser.argdown();\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n  it(\"can return errors\", function(){\n    let source = \"Text <Title>:\\n\\n+ text\";\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    parser.argdown();\n    //console.log(parser.errors[0]);\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.exist;\n  });\n  it(\"can escape characters\", function () {\n    let source = \"<Title>: text \\\\[text\\\\]\";\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    parser.argdown();\n    expect(lexResult.errors).to.be.empty;\n    expect(parser.errors).to.be.empty;\n  });\n  // it(\"can return custom NoViableAltMessage\", function () {\n  //   let source = `asdda\n  // + adas [sdsd] sadd`;\n  //   let lexResult = lexer.tokenize(source);\n  //   parser.input = lexResult.tokens;\n  //   let parseResult = parser.argdown();\n  //   console.log(parser.errors[0]);\n  // });\n});\n\ndescribe(\"ArgdownTreeWalker\", function() {\n  it(\"can walk\", function(){\n    let source = \"Hallo Welt!\";\n    let lexResult = lexer.tokenize(source);\n    parser.input = lexResult.tokens;\n    let ast = parser.argdown();\n    let statements = 0;\n    walker.on('statementEntry',(request, response, node)=>{statements++; expect(node.name).to.equal('statement');});\n    walker.walk({}, {ast: ast});\n    expect(statements).to.equal(1);\n  });\n});\n"]}