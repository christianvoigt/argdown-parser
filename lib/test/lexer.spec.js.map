{"version":3,"sources":["../../test/lexer.spec.js"],"names":["i","currentTokens","expectToken","tokenType","to","be","true","expectTokenLocation","startOffset","endOffset","startLine","endLine","startColumn","endColumn","token","equal","startTest","tokens","lexer","describe","it","source","readFileSync","result","tokenize","OutgoingSupport","OutgoingAttack","IncomingSupport","IncomingAttack","Contradiction","IncomingUndercut","OutgoingUndercut","Freestyle","Emptyline","HeadingStart","ArgumentMention","StatementMention","UnusedControlChar","Indent","UnorderedListItem","OrderedListItem","Dedent","StatementNumber","InferenceStart","ListDelimiter","MetadataStart","Colon","MetadataStatementEnd","MetadataEnd","InferenceEnd","UnderscoreBoldStart","UnderscoreBoldEnd","UnderscoreItalicStart","UnderscoreItalicEnd","AsteriskBoldStart","AsteriskBoldEnd","AsteriskItalicStart","AsteriskItalicEnd","StatementReference","StatementDefinition","ArgumentReference","ArgumentDefinition","Link","Tag","length","EscapedChar"],"mappings":";;AACA;;AACA;;;;AACA;;AACA;;;;AAJA;AAMA,IAAIA,IAAI,CAAR;AACA,IAAIC,gBAAgB,IAApB;AACA,SAASC,WAAT,CAAqBC,SAArB,EAAgC;AAC5B;AACA,sBAAO,8BAAaF,cAAcD,CAAd,CAAb,EAA+BG,SAA/B,CAAP,EAAkDC,EAAlD,CAAqDC,EAArD,CAAwDC,IAAxD;AACAN;AACH;AACD,SAASO,mBAAT,CAA6BC,WAA7B,EAA0CC,SAA1C,EAAqDC,SAArD,EAAgEC,OAAhE,EAAyEC,WAAzE,EAAsFC,SAAtF,EAAiG;AAC7F,QAAIC,QAAQb,cAAcD,CAAd,CAAZ;AACA,sBAAOc,MAAMN,WAAb,EAA0BJ,EAA1B,CAA6BW,KAA7B,CAAmCP,WAAnC;AACA,sBAAOM,MAAML,SAAb,EAAwBL,EAAxB,CAA2BW,KAA3B,CAAiCN,SAAjC;AACA,sBAAOK,MAAMJ,SAAb,EAAwBN,EAAxB,CAA2BW,KAA3B,CAAiCL,SAAjC;AACA,sBAAOI,MAAMH,OAAb,EAAsBP,EAAtB,CAAyBW,KAAzB,CAA+BJ,OAA/B;AACA,sBAAOG,MAAMF,WAAb,EAA0BR,EAA1B,CAA6BW,KAA7B,CAAmCH,WAAnC;AACA,sBAAOE,MAAMD,SAAb,EAAwBT,EAAxB,CAA2BW,KAA3B,CAAiCF,SAAjC;AACAb;AACH;AACD,SAASgB,SAAT,CAAmBC,MAAnB,EAA2B;AACvBhB,oBAAgBgB,MAAhB;AACAjB,QAAI,CAAJ;AACH;AACD,IAAMkB,kCAAN;;AAEAC,SAAS,OAAT,EAAkB,YAAW;AACzBC,OAAG,4CAAH,EAAiD,YAAW;AACxD,YAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMQ,cAAlB;AACAxB,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMQ,cAAlB;AACAxB,oBAAYgB,MAAMS,eAAlB;AACAzB,oBAAYgB,MAAMU,cAAlB;AACA1B,oBAAYgB,MAAMW,aAAlB;AACA3B,oBAAYgB,MAAMY,gBAAlB;AACA5B,oBAAYgB,MAAMa,gBAAlB;AACH,KAbD;AAcAX,OAAG,+CAAH,EAAoD,YAAW;AAC3D,YAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACH,KAVD;AAWAZ,OAAG,kBAAH,EAAuB,YAAW;AAC9B,YAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMgB,YAAlB;AACAhC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMiB,eAAlB;AACAjC,oBAAYgB,MAAMkB,gBAAlB;AACAlC,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMiB,eAAlB;AACAjC,oBAAYgB,MAAMkB,gBAAlB;AACH,KAbD;AAcAhB,OAAG,kBAAH,EAAuB,YAAW;AAC9B,YAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMgB,YAAlB;AACAhC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMgB,YAAlB;AACAhC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACH,KAbD;AAcAZ,OAAG,qCAAH,EAA0C,YAAW;AACjD,YAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMqB,iBAAlB;AACArC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMqB,iBAAlB;AACArC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMsB,eAAlB;AACAtC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMqB,iBAAlB;AACArC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMuB,MAAlB;AACH,KAnCD;AAoCArB,OAAG,oCAAH,EAAyC,YAAW;AAChD,YAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMwB,eAAlB;AACAxC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMwB,eAAlB;AACAxC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMyB,cAAlB;AACAzC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM0B,aAAlB;AACA1C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM2B,aAAlB;AACA3C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM4B,KAAlB;AACA5C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM0B,aAAlB;AACA1C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM6B,oBAAlB;AACA7C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM4B,KAAlB;AACA5C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM0B,aAAlB;AACA1C,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM8B,WAAlB;AACA9C,oBAAYgB,MAAM+B,YAAlB;AACA/C,oBAAYgB,MAAMwB,eAAlB;AACAxC,oBAAYgB,MAAMc,SAAlB;AACH,KA5BD;AA6BAZ,OAAG,yBAAH,EAA8B,YAAW;AACrC,YAAIC,SAAS,aAAGC,YAAH,CAAgB,uCAAhB,EAAyD,MAAzD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACH,KAXD;AAYAZ,OAAG,kCAAH,EAAuC,YAAW;AAC9C,YAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMQ,cAAlB;AACAxB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACH,KAhBD;AAiBArB,OAAG,8BAAH,EAAmC,YAAW;AAC1C,YAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMiC,iBAAlB;AACAjD,oBAAYgB,MAAMkC,qBAAlB;AACAlD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmC,mBAAlB;AACAnD,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMqC,eAAlB;AACArD,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMqC,eAAlB;;AAEArD,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMkC,qBAAlB;AACAlD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmC,mBAAlB;AACAnD,oBAAYgB,MAAMiC,iBAAlB;;AAEAjD,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMiC,iBAAlB;AACAjD,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMiC,iBAAlB;AACAjD,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMqC,eAAlB;AACArD,oBAAYgB,MAAMqC,eAAlB;AACArD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMkC,qBAAlB;AACAlD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmC,mBAAlB;AACAnD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMqC,eAAlB;AACArD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMiC,iBAAlB;AACAjD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMsC,mBAAlB;AACAtD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuC,iBAAlB;AACAvD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMkC,qBAAlB;AACAlD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmC,mBAAlB;AACAnD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMoC,iBAAlB;AACApD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMqC,eAAlB;AACArD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMgC,mBAAlB;AACAhD,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMiC,iBAAlB;AACAjD,oBAAYgB,MAAMmB,iBAAlB;AACH,KAxFD;AAyFAjB,OAAG,6BAAH,EAAkC,YAAW;AACzC,YAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMQ,cAAlB;AACAxB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMQ,cAAlB;AACAxB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMS,eAAlB;AACAzB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMU,cAAlB;AACA1B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACH,KAzBD;AA0BArB,OAAG,iEAAH,EAAsE,YAAW;AAC7E,YAAIC,SAAS,aAAGC,YAAH,CAAgB,6CAAhB,EAA+D,MAA/D,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMwC,kBAAlB;AACAxD,oBAAYgB,MAAMyC,mBAAlB;AACAzD,oBAAYgB,MAAM0C,iBAAlB;AACA1D,oBAAYgB,MAAM2C,kBAAlB;AACA3D,oBAAYgB,MAAMc,SAAlB;AACH,KATD;AAUAZ,OAAG,qBAAH,EAA0B,YAAW;AACjC,YAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMc,SAAlB;AACH,KARD;AASAZ,OAAG,8BAAH,EAAmC,YAAW;AAC1C,YAAIC,SAAS,aAAGC,YAAH,CAAgB,qCAAhB,EAAuD,MAAvD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACAf,oBAAYgB,MAAMyC,mBAAlB;AACAzD,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMmB,iBAAlB;AACAnC,oBAAYgB,MAAM4C,IAAlB;AACA5D,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM6C,GAAlB;AACA7D,oBAAYgB,MAAM6C,GAAlB;AACA7D,oBAAYgB,MAAM6C,GAAlB;AACH,KAdD;AAeA3C,OAAG,8CAAH,EAAmD,YAAW;AAC1D,YAAIC,SAAS,aAAGC,YAAH,CAAgB,yCAAhB,EAA2D,MAA3D,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA,0BAAOM,OAAON,MAAP,CAAc+C,MAArB,EAA6B5D,EAA7B,CAAgCW,KAAhC,CAAsC,CAAtC;AACAb,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMyC,mBAAlB;AACAzD,oBAAYgB,MAAMc,SAAlB;AACH,KARD;AASAZ,OAAG,8BAAH,EAAmC,YAAW;AAC1C,YAAIC,SAAS,aAAGC,YAAH,CAAgB,2CAAhB,EAA6D,MAA7D,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACA;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACAvC,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMwB,eAAlB;AACAxC,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMyB,cAAlB;AACAzC,oBAAYgB,MAAM+B,YAAlB;AACA/C,oBAAYgB,MAAMwB,eAAlB;AACAxC,oBAAYgB,MAAMc,SAAlB;AACH,KAlBD;AAmBAZ,OAAG,uBAAH,EAA4B,YAAW;AACnC,YAAIC,SAAS,aAAGC,YAAH,CAAgB,oCAAhB,EAAsD,MAAtD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACA;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM+C,WAAlB;AACA/D,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM+C,WAAlB;AACA/D,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM+C,WAAlB;AACA/D,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAM+C,WAAlB;AACA/D,oBAAYgB,MAAM+C,WAAlB;AACA/D,oBAAYgB,MAAMc,SAAlB;AACH,KAhBD;AAiBAZ,OAAG,sCAAH,EAA2C,YAAW;AAClD,YAAIC,SAAS,aAAGC,YAAH,CAAgB,sCAAhB,EAAwD,MAAxD,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACAV,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EANkD,CAMX;AACvCA,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,4BAAoB,CAApB,EAAuB,EAAvB,EAA2B,CAA3B,EAA8B,CAA9B,EAAiC,CAAjC,EAAoC,CAApC,EATkD,CASV;AACxCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAVkD,CAUT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC;AACAA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EAZkD,CAYP;AAC3CA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,CAAtC,EAbkD,CAaR;AAC1CA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAdkD,CAcT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAfkD,CAeT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAhBkD,CAgBT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAjBkD,CAiBT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC;AACAA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAnBkD,CAmBT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,EAArC,EApBkD,CAoBR;AAC1CA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EArBkD,CAqBP;AAC3CA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAtBkD,CAsBT;AACzCA,4BAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAvBkD,CAuBT;AAC5C,KAxBD;AAyBAa,OAAG,6DAAH,EAAkE,YAAW;AACzE,YAAIC,SAAS,aAAGC,YAAH,CAAgB,uDAAhB,EAAyE,MAAzE,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACA;AACAV,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EANyE,CAMlC;AACvCA,4BAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EAPyE,CAOlC;AAC1C,KARD;AASAa,OAAG,mCAAH,EAAwC,YAAW;AAC/C,YAAIC,SAAS,aAAGC,YAAH,CAAgB,+CAAhB,EAAiE,MAAjE,CAAb;AACA,YAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,kBAAUO,OAAON,MAAjB;AACA;AACA;AACAf,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMe,SAAlB;AACA/B,oBAAYgB,MAAMoB,MAAlB;AACApC,oBAAYgB,MAAMO,eAAlB;AACAvB,oBAAYgB,MAAMc,SAAlB;AACA9B,oBAAYgB,MAAMuB,MAAlB;AACH,KAZD;AAaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACH,CAjZD","file":"lexer.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from \"chai\";\nimport fs from \"fs\";\nimport { ArgdownLexer } from \"../src/ArgdownLexer.js\";\nimport { tokenMatcher } from \"chevrotain\";\n\nlet i = 0;\nlet currentTokens = null;\nfunction expectToken(tokenType) {\n    //expect(currentTokens[i]).to.be.an.instanceof(tokenType);\n    expect(tokenMatcher(currentTokens[i], tokenType)).to.be.true;\n    i++;\n}\nfunction expectTokenLocation(startOffset, endOffset, startLine, endLine, startColumn, endColumn) {\n    var token = currentTokens[i];\n    expect(token.startOffset).to.equal(startOffset);\n    expect(token.endOffset).to.equal(endOffset);\n    expect(token.startLine).to.equal(startLine);\n    expect(token.endLine).to.equal(endLine);\n    expect(token.startColumn).to.equal(startColumn);\n    expect(token.endColumn).to.equal(endColumn);\n    i++;\n}\nfunction startTest(tokens) {\n    currentTokens = tokens;\n    i = 0;\n}\nconst lexer = ArgdownLexer;\n\ndescribe(\"Lexer\", function() {\n    it(\"recognizes incoming and outgoing relations\", function() {\n        let source = fs.readFileSync(\"./test/lexer-relations.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.OutgoingAttack);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.OutgoingAttack);\n        expectToken(lexer.IncomingSupport);\n        expectToken(lexer.IncomingAttack);\n        expectToken(lexer.Contradiction);\n        expectToken(lexer.IncomingUndercut);\n        expectToken(lexer.OutgoingUndercut);\n    });\n    it(\"can distinguish between Emptyline and Newline\", function() {\n        let source = fs.readFileSync(\"./test/lexer-emptyline.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can lex mentions\", function() {\n        let source = fs.readFileSync(\"./test/lexer-mentions.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.HeadingStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.ArgumentMention);\n        expectToken(lexer.StatementMention);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.ArgumentMention);\n        expectToken(lexer.StatementMention);\n    });\n    it(\"can lex headings\", function() {\n        let source = fs.readFileSync(\"./test/lexer-heading.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.HeadingStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.HeadingStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can lex ordered and unordered lists\", function() {\n        let source = fs.readFileSync(\"./test/lexer-lists.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Indent);\n        expectToken(lexer.UnorderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.UnorderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.OrderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.UnorderedListItem);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Dedent);\n    });\n    it(\"can lex an argument reconstruction\", function() {\n        let source = fs.readFileSync(\"./test/lexer-argument.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.StatementNumber);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.StatementNumber);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.InferenceStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.ListDelimiter);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.MetadataStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Colon);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.ListDelimiter);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.MetadataStatementEnd);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Colon);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.ListDelimiter);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.MetadataEnd);\n        expectToken(lexer.InferenceEnd);\n        expectToken(lexer.StatementNumber);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can dedent on Emptyline\", function() {\n        let source = fs.readFileSync(\"./test/lexer-emptyline-dedent.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can ignore Newlines in relations\", function() {\n        let source = fs.readFileSync(\"./test/lexer-linebreak.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.OutgoingAttack);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n    });\n    it(\"can lex bold and italic text\", function() {\n        let source = fs.readFileSync(\"./test/lexer-italic-bold.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        // console.log(lexer.tokensToString(result.tokens));\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldEnd);\n        expectToken(lexer.UnderscoreItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreItalicEnd);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskBoldEnd);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.AsteriskBoldEnd);\n\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.UnderscoreItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreItalicEnd);\n        expectToken(lexer.UnderscoreBoldEnd);\n\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.UnderscoreBoldEnd);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldEnd);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskBoldEnd);\n        expectToken(lexer.AsteriskBoldEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.UnderscoreItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreItalicEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskBoldEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.AsteriskItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskItalicEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.UnderscoreItalicStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreItalicEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.AsteriskBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.AsteriskBoldEnd);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.UnderscoreBoldStart);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnderscoreBoldEnd);\n        expectToken(lexer.UnusedControlChar);\n    });\n    it(\"can lex complex indentation\", function() {\n        let source = fs.readFileSync(\"./test/lexer-indentation.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.OutgoingAttack);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingAttack);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.IncomingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.IncomingAttack);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n    });\n    it(\"can recognize argument and statement references and definitions\", function() {\n        let source = fs.readFileSync(\"./test/lexer-definitions-references.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.StatementReference);\n        expectToken(lexer.StatementDefinition);\n        expectToken(lexer.ArgumentReference);\n        expectToken(lexer.ArgumentDefinition);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can ignore comments\", function() {\n        let source = fs.readFileSync(\"./test/lexer-comment.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can recognize links and tags\", function() {\n        let source = fs.readFileSync(\"./test/lexer-links-and-tags.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokensToString(result.tokens));\n        expectToken(lexer.StatementDefinition);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.UnusedControlChar);\n        expectToken(lexer.Link);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Tag);\n        expectToken(lexer.Tag);\n        expectToken(lexer.Tag);\n    });\n    it(\"can ignore trailing Emptyline before comment\", function() {\n        let source = fs.readFileSync(\"./test/lexer-trailing-emptyline.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        expect(result.tokens.length).to.equal(3);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.StatementDefinition);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can lex Windows line endings\", function() {\n        let source = fs.readFileSync(\"./test/lexer-windows-line-endings.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokensToString(result.tokens));\n        //expect(result.tokens.length).to.equal(5);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.StatementNumber);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.InferenceStart);\n        expectToken(lexer.InferenceEnd);\n        expectToken(lexer.StatementNumber);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can lex escaped chars\", function() {\n        let source = fs.readFileSync(\"./test/lexer-escaped-chars.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokensToString(result.tokens));\n        //expect(result.tokens.length).to.equal(5);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.EscapedChar);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.EscapedChar);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.EscapedChar);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.EscapedChar);\n        expectToken(lexer.EscapedChar);\n        expectToken(lexer.Freestyle);\n    });\n    it(\"can save correct token location data\", function() {\n        let source = fs.readFileSync(\"./test/lexer-token-locations.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokenLocationsToString(result.tokens));\n        expectTokenLocation(0, 0, 1, 1, 1, 1);\n        expectTokenLocation(2, 2, 2, 2, 1, 1); //offset = 2 because of ignored line break\n        expectTokenLocation(4, 5, 3, 3, 1, 2);\n        expectTokenLocation(6, 6, 3, 3, 3, 3);\n        expectTokenLocation(7, 11, 3, 3, 4, 8); //@[A]\n        expectTokenLocation(12, 12, 3, 3, 9, 9); //ItalicStart\n        expectTokenLocation(13, 13, 3, 3, 10, 10);\n        expectTokenLocation(14, 14, 3, 3, 11, 11); //ItalicEnd\n        expectTokenLocation(15, 16, 3, 4, 12, 1); //Emptyline\n        expectTokenLocation(17, 20, 5, 5, 1, 4); //<B>:\n        expectTokenLocation(22, 22, 5, 5, 6, 6); //skipped whitespace at offset 21\n        expectTokenLocation(24, 27, 6, 6, 1, 4); // Indent (4 spaces)\n        expectTokenLocation(23, 28, 5, 6, 7, 5); // + (including linebreak and 4 spaces for indentation)\n        expectTokenLocation(30, 30, 6, 6, 7, 7);\n        expectTokenLocation(32, 39, 7, 7, 1, 8); // Indent (8 spaces)\n        expectTokenLocation(31, 41, 6, 7, 8, 10); // -> including linebreak and spaces\n        expectTokenLocation(43, 43, 7, 7, 12, 12); // skipped whitespace at offset 42\n        expectTokenLocation(44, 44, 8, 8, 1, 1); // Dedent is always at next line at column 1\n        expectTokenLocation(44, 44, 8, 8, 1, 1); // Dedent is always at next line at column 1\n    });\n    it(\"can save correct token location data if first line is empty\", function() {\n        let source = fs.readFileSync(\"./test/lexer-token-locations-first-line-empty.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokenLocationsToString(result.tokens));\n        //expect(result.tokens.length).to.equal(5);\n        expectTokenLocation(1, 1, 2, 2, 1, 1); //First newline skipped\n        expectTokenLocation(3, 3, 3, 3, 1, 1); //Second newline skipped\n    });\n    it(\"can lex relation after empty line\", function() {\n        let source = fs.readFileSync(\"./test/lexer-relation-after-emptyline.argdown\", \"utf8\");\n        const result = lexer.tokenize(source);\n        startTest(result.tokens);\n        //console.log(lexer.tokensToString(result.tokens));\n        //expect(result.tokens.length).to.equal(5);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Emptyline);\n        expectToken(lexer.Indent);\n        expectToken(lexer.OutgoingSupport);\n        expectToken(lexer.Freestyle);\n        expectToken(lexer.Dedent);\n    });\n    // it(\"can lex statement references, definitions and mentions by number\", function () {\n    //   let source = fs.readFileSync(\"./test/lexer-statements-by-number.argdown\", 'utf8');\n    //   const result = lexer.tokenize(source);\n    //   startTest(result.tokens);\n    //   console.log(lexer.tokensToString(result.tokens));\n    //   //expect(result.tokens.length).to.equal(5);\n    //   expectToken(lexer.StatementDefinitionByNumber);\n    //   expectToken(lexer.Freestyle);\n    //   expectToken(lexer.StatementReferenceByNumber);\n    //   expectToken(lexer.StatementMentionByNumber);\n    //   // expectToken(lexer.Dedent);\n    // });\n});\n"]}