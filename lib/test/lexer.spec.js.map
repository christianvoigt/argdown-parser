{"version":3,"sources":["../../test/lexer.spec.js"],"names":["i","currentTokens","expectToken","tokenType","to","be","an","instanceof","startTest","tokens","lexer","describe","it","source","readFileSync","result","tokenize","OutgoingSupport","OutgoingAttack","IncomingSupport","IncomingAttack","Freestyle","Emptyline","HeadingStart","ArgumentMention","StatementMention","UnusedControlChar","Indent","UnorderedListItem","OrderedListItem","Dedent","ArgumentStatementStart","InferenceStart","ListDelimiter","MetadataStart","Colon","MetadataStatementEnd","MetadataEnd","InferenceEnd","UnderscoreBoldStart","UnderscoreBoldEnd","UnderscoreItalicStart","UnderscoreItalicEnd","AsteriskBoldStart","AsteriskBoldEnd","AsteriskItalicStart","AsteriskItalicEnd","StatementReference","StatementDefinition","ArgumentReference","ArgumentDefinition","Link"],"mappings":";;AACA;;AACA;;;;AACA;;;;AAEA,IAAIA,IAAI,CAAR,C,CALA;;AAMA,IAAIC,gBAAgB,IAApB;AACA,SAASC,WAAT,CAAqBC,SAArB,EAA+B;AAC7B,oBAAOF,cAAcD,CAAd,CAAP,EAAyBI,EAAzB,CAA4BC,EAA5B,CAA+BC,EAA/B,CAAkCC,UAAlC,CAA6CJ,SAA7C;AACAH;AACD;AACD,SAASQ,SAAT,CAAmBC,MAAnB,EAA0B;AACxBR,kBAAgBQ,MAAhB;AACAT,MAAI,CAAJ;AACD;AACD,IAAMU,kCAAN;;AAGAC,SAAS,OAAT,EAAkB,YAAW;AAC3BC,KAAG,4CAAH,EAAiD,YAAU;AACzD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMQ,cAAlB;AACAhB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMQ,cAAlB;AACAhB,gBAAYQ,MAAMS,eAAlB;AACAjB,gBAAYQ,MAAMU,cAAlB;AACD,GAVD;AAWAR,KAAG,+CAAH,EAAoD,YAAU;AAC5D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACD,GAVD;AAWAT,KAAG,kBAAH,EAAuB,YAAU;AAC/B,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMa,YAAlB;AACArB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMc,eAAlB;AACAtB,gBAAYQ,MAAMe,gBAAlB;AACAvB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMgB,iBAAlB;AACAxB,gBAAYQ,MAAMc,eAAlB;AACAtB,gBAAYQ,MAAMe,gBAAlB;AACD,GAbD;AAcEb,KAAG,kBAAH,EAAuB,YAAU;AACjC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMa,YAAlB;AACArB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMa,YAAlB;AACArB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACD,GAbC;AAcFT,KAAG,qCAAH,EAA0C,YAAU;AAClD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMkB,iBAAlB;AACA1B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMkB,iBAAlB;AACA1B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMmB,eAAlB;AACA3B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMkB,iBAAlB;AACA1B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMoB,MAAlB;AACD,GAnCD;AAoCElB,KAAG,oCAAH,EAAyC,YAAU;AACnD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMqB,sBAAlB;AACA7B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMqB,sBAAlB;AACA7B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMsB,cAAlB;AACA9B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMuB,aAAlB;AACA/B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMwB,aAAlB;AACAhC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMyB,KAAlB;AACAjC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMuB,aAAlB;AACA/B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM0B,oBAAlB;AACAlC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMyB,KAAlB;AACAjC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMuB,aAAlB;AACA/B,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM2B,WAAlB;AACAnC,gBAAYQ,MAAM4B,YAAlB;AACApC,gBAAYQ,MAAMqB,sBAAlB;AACA7B,gBAAYQ,MAAMW,SAAlB;AACD,GA5BC;AA6BAT,KAAG,yBAAH,EAA6B,YAAU;AACvC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,uCAAhB,EAAyD,MAAzD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACD,GAXC;AAYFT,KAAG,kCAAH,EAAsC,YAAU;AAC9C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMQ,cAAlB;AACAhB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACD,GAhBD;AAiBAlB,KAAG,8BAAH,EAAkC,YAAU;AAC1C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM6B,mBAAlB;AACArC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM8B,iBAAlB;AACAtC,gBAAYQ,MAAM+B,qBAAlB;AACAvC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMgC,mBAAlB;AACAxC,gBAAYQ,MAAMiC,iBAAlB;AACAzC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMkC,eAAlB;AACA1C,gBAAYQ,MAAMmC,mBAAlB;AACA3C,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoC,iBAAlB;AACA5C,gBAAYQ,MAAMiC,iBAAlB;AACAzC,gBAAYQ,MAAMmC,mBAAlB;AACA3C,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoC,iBAAlB;AACA5C,gBAAYQ,MAAMkC,eAAlB;AACA1C,gBAAYQ,MAAM6B,mBAAlB;AACArC,gBAAYQ,MAAM+B,qBAAlB;AACAvC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMgC,mBAAlB;AACAxC,gBAAYQ,MAAM8B,iBAAlB;AACAtC,gBAAYQ,MAAM6B,mBAAlB;AACArC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMmC,mBAAlB;AACA3C,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoC,iBAAlB;AACA5C,gBAAYQ,MAAM8B,iBAAlB;AACAtC,gBAAYQ,MAAMmC,mBAAlB;AACA3C,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM6B,mBAAlB;AACArC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAM8B,iBAAlB;AACAtC,gBAAYQ,MAAMoC,iBAAlB;AACA5C,gBAAYQ,MAAMiC,iBAAlB;AACAzC,gBAAYQ,MAAMiC,iBAAlB;AACAzC,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMkC,eAAlB;AACA1C,gBAAYQ,MAAMkC,eAAlB;AACD,GA5CD;AA6CGhC,KAAG,6BAAH,EAAkC,YAAW;AAC7C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMQ,cAAlB;AACAhB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMO,eAAlB;AACAf,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMQ,cAAlB;AACAhB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMiB,MAAlB;AACAzB,gBAAYQ,MAAMS,eAAlB;AACAjB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMoB,MAAlB;AACA5B,gBAAYQ,MAAMU,cAAlB;AACAlB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMoB,MAAlB;AAED,GA1BC;AA2BFlB,KAAG,iEAAH,EAAsE,YAAU;AAC9E,QAAIC,SAAS,aAAGC,YAAH,CAAgB,6CAAhB,EAA+D,MAA/D,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMqC,kBAAlB;AACA7C,gBAAYQ,MAAMsC,mBAAlB;AACA9C,gBAAYQ,MAAMuC,iBAAlB;AACA/C,gBAAYQ,MAAMwC,kBAAlB;AACAhD,gBAAYQ,MAAMW,SAAlB;AACD,GATD;AAUAT,KAAG,qBAAH,EAA0B,YAAU;AAClC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMY,SAAlB;AACApB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMW,SAAlB;AACD,GARD;AASAT,KAAG,qBAAH,EAA0B,YAAU;AAClC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAP,gBAAYQ,MAAMsC,mBAAlB;AACA9C,gBAAYQ,MAAMgB,iBAAlB;AACAxB,gBAAYQ,MAAMW,SAAlB;AACAnB,gBAAYQ,MAAMgB,iBAAlB;AACAxB,gBAAYQ,MAAMyC,IAAlB;AACAjD,gBAAYQ,MAAMW,SAAlB;AACD,GAVD;AAWD,CAvPF","file":"lexer.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from 'chai';\nimport fs from 'fs';\nimport {ArgdownLexer} from '../src/ArgdownLexer.js';\n\nlet i = 0;\nlet currentTokens = null;\nfunction expectToken(tokenType){\n  expect(currentTokens[i]).to.be.an.instanceof(tokenType);\n  i++;\n}\nfunction startTest(tokens){\n  currentTokens = tokens;\n  i = 0;\n}\nconst lexer = ArgdownLexer;\n\n\ndescribe(\"Lexer\", function() {\n  it(\"recognizes incoming and outgoing relations\", function(){\n    let source = fs.readFileSync(\"./test/lexer-relations.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.IncomingAttack);\n  });\n  it(\"can distinguish between Emptyline and Newline\", function(){\n    let source = fs.readFileSync(\"./test/lexer-emptyline.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex mentions\", function(){\n    let source = fs.readFileSync(\"./test/lexer-mentions.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n  });\n    it(\"can lex headings\", function(){\n    let source = fs.readFileSync(\"./test/lexer-heading.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex ordered and unordered lists\", function(){\n    let source = fs.readFileSync(\"./test/lexer-lists.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n  });\n    it(\"can lex an argument reconstruction\", function(){\n    let source = fs.readFileSync(\"./test/lexer-argument.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.InferenceStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStatementEnd);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataEnd);\n    expectToken(lexer.InferenceEnd);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n  });\n    it(\"can dedent on Emptyline\",function(){\n    let source = fs.readFileSync(\"./test/lexer-emptyline-dedent.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore Newlines in relations\",function(){\n    let source = fs.readFileSync(\"./test/lexer-linebreak.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex bold and italic text\",function(){\n    let source = fs.readFileSync(\"./test/lexer-italic-bold.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n  });\n     it(\"can lex complex indentation\", function() {\n     let source = fs.readFileSync(\"./test/lexer-indentation.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.OutgoingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.IncomingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.IncomingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Dedent);\n\n   });\n   it(\"can recognize argument and statement references and definitions\", function(){\n     let source = fs.readFileSync(\"./test/lexer-definitions-references.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.StatementReference);\n     expectToken(lexer.StatementDefinition);\n     expectToken(lexer.ArgumentReference);\n     expectToken(lexer.ArgumentDefinition);\n     expectToken(lexer.Freestyle);\n   });\n   it(\"can ignore comments\", function(){\n     let source = fs.readFileSync(\"./test/lexer-comment.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Emptyline);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Freestyle);\n   });\n   it(\"can recognize links\", function(){\n     let source = fs.readFileSync(\"./test/lexer-links.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.StatementDefinition);\n     expectToken(lexer.UnusedControlChar);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.UnusedControlChar);\n     expectToken(lexer.Link);\n     expectToken(lexer.Freestyle);\n   });\n });\n"]}