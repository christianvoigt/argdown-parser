{"version":3,"sources":["../../test/lexer.spec.ts"],"names":["i","currentTokens","expectToken","tokenType","chevrotain","tokenMatcher","to","be","true","expectTokenLocation","startOffset","endOffset","startLine","endLine","startColumn","endColumn","token","equal","startTest","tokens","it","source","fs","readFileSync","result","lexer","tokenize","OutgoingSupport","OutgoingAttack","IncomingSupport","IncomingAttack","Contradiction","IncomingUndercut","OutgoingUndercut","Freestyle","Emptyline","HeadingStart","ArgumentMention","StatementMention","UnusedControlChar","Indent","UnorderedListItem","OrderedListItem","Dedent","StatementNumber","InferenceStart","ListDelimiter","MetaData","InferenceEnd","UnderscoreBoldStart","UnderscoreBoldEnd","UnderscoreItalicStart","UnderscoreItalicEnd","AsteriskBoldStart","AsteriskBoldEnd","AsteriskItalicStart","AsteriskItalicEnd","StatementReference","StatementDefinition","ArgumentReference","ArgumentDefinition","Link","Tag","length","EscapedChar","FrontMatter"],"mappings":";;AAAA;;AACA;;AACA;;AACA;;AACA;;;;AAEA,IAAIA,IAAI,CAAR;AACA,IAAIC,gBAAqC,EAAzC;;AACA,SAASC,WAAT,CAAqBC,SAArB,EAAsD;AACpD;AACA,oBAAOC,WAAWC,YAAX,CAAwBJ,cAAcD,CAAd,CAAxB,EAA0CG,SAA1C,CAAP,EAA6DG,EAA7D,CAAgEC,EAAhE,CAAmEC,IAAnE;AACAR;AACD;;AACD,SAASS,mBAAT,CACEC,WADF,EAEEC,SAFF,EAGEC,SAHF,EAIEC,OAJF,EAKEC,WALF,EAMEC,SANF,EAOE;AACA,MAAIC,QAAQf,cAAcD,CAAd,CAAZ;AACA,oBAAOgB,MAAMN,WAAb,EAA0BJ,EAA1B,CAA6BW,KAA7B,CAAmCP,WAAnC;AACA,oBAAOM,MAAML,SAAb,EAAwBL,EAAxB,CAA2BW,KAA3B,CAAiCN,SAAjC;AACA,oBAAOK,MAAMJ,SAAb,EAAwBN,EAAxB,CAA2BW,KAA3B,CAAiCL,SAAjC;AACA,oBAAOI,MAAMH,OAAb,EAAsBP,EAAtB,CAAyBW,KAAzB,CAA+BJ,OAA/B;AACA,oBAAOG,MAAMF,WAAb,EAA0BR,EAA1B,CAA6BW,KAA7B,CAAmCH,WAAnC;AACA,oBAAOE,MAAMD,SAAb,EAAwBT,EAAxB,CAA2BW,KAA3B,CAAiCF,SAAjC;AACAf;AACD;;AACD,SAASkB,SAAT,CAAmBC,MAAnB,EAAgD;AAC9ClB,kBAAgBkB,MAAhB;AACAnB,MAAI,CAAJ;AACD;;AAED,qBAAS,OAAT,EAAkB,YAAW;AAC3BoB,KAAG,4CAAH,EAAiD,YAAW;AAC1D,QAAIC,SAASC,GAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf,CAF0D,CAG1D;;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMG,cAAlB;AACA1B,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMG,cAAlB;AACA1B,gBAAYuB,MAAMI,eAAlB;AACA3B,gBAAYuB,MAAMK,cAAlB;AACA5B,gBAAYuB,MAAMM,aAAlB;AACA7B,gBAAYuB,MAAMO,gBAAlB;AACA9B,gBAAYuB,MAAMQ,gBAAlB;AACD,GAdD;AAeAb,KAAG,+CAAH,EAAoD,YAAW;AAC7D,QAAIC,SAASC,GAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACD,GAVD;AAWAd,KAAG,kBAAH,EAAuB,YAAW;AAChC,QAAIC,SAASC,GAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMW,YAAlB;AACAlC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMY,eAAlB;AACAnC,gBAAYuB,MAAMa,gBAAlB;AACApC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAMY,eAAlB;AACAnC,gBAAYuB,MAAMa,gBAAlB;AACD,GAbD;AAcAlB,KAAG,kBAAH,EAAuB,YAAW;AAChC,QAAIC,SAASC,GAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMW,YAAlB;AACAlC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMW,YAAlB;AACAlC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACD,GAbD;AAcAd,KAAG,qCAAH,EAA0C,YAAW;AACnD,QAAIC,SAASC,GAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf,CAFmD,CAGnD;;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMgB,iBAAlB;AACAvC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMgB,iBAAlB;AACAvC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMiB,eAAlB;AACAxC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMgB,iBAAlB;AACAvC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMkB,MAAlB;AACD,GApCD;AAqCAvB,KAAG,oCAAH,EAAyC,YAAW;AAClD,QAAIC,SAASC,GAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf,CAFkD,CAGlD;;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMmB,eAAlB;AACA1C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMmB,eAAlB;AACA1C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMoB,cAAlB;AACA3C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMqB,aAAlB;AACA5C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMsB,QAAlB;AACA7C,gBAAYuB,MAAMuB,YAAlB;AACA9C,gBAAYuB,MAAMmB,eAAlB;AACA1C,gBAAYuB,MAAMS,SAAlB;AACD,GAjBD;AAkBAd,KAAG,yBAAH,EAA8B,YAAW;AACvC,QAAIC,SAASC,GAAGC,YAAH,CAAgB,uCAAhB,EAAyD,MAAzD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACD,GAXD;AAYAd,KAAG,kCAAH,EAAuC,YAAW;AAChD,QAAIC,SAASC,GAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMG,cAAlB;AACA1B,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACD,GAhBD;AAiBAvB,KAAG,8BAAH,EAAmC,YAAW;AAC5C,QAAIC,SAASC,GAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAH4C,CAI5C;;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMyB,iBAAlB;AACAhD,gBAAYuB,MAAM0B,qBAAlB;AACAjD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM2B,mBAAlB;AACAlD,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM6B,eAAlB;AACApD,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAM6B,eAAlB;AAEApD,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAM0B,qBAAlB;AACAjD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM2B,mBAAlB;AACAlD,gBAAYuB,MAAMyB,iBAAlB;AAEAhD,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAMyB,iBAAlB;AACAhD,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMyB,iBAAlB;AACAhD,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM6B,eAAlB;AACApD,gBAAYuB,MAAM6B,eAAlB;AACApD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM0B,qBAAlB;AACAjD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM2B,mBAAlB;AACAlD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM6B,eAAlB;AACApD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMyB,iBAAlB;AACAhD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM8B,mBAAlB;AACArD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM+B,iBAAlB;AACAtD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM0B,qBAAlB;AACAjD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM2B,mBAAlB;AACAlD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAM4B,iBAAlB;AACAnD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAM6B,eAAlB;AACApD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAMwB,mBAAlB;AACA/C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMyB,iBAAlB;AACAhD,gBAAYuB,MAAMc,iBAAlB;AACD,GAxFD;AAyFAnB,KAAG,6BAAH,EAAkC,YAAW;AAC3C,QAAIC,SAASC,GAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMG,cAAlB;AACA1B,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMG,cAAlB;AACA1B,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAMI,eAAlB;AACA3B,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMK,cAAlB;AACA5B,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACD,GAzBD;AA0BAvB,KAAG,iEAAH,EAAsE,YAAW;AAC/E,QAAIC,SAASC,GAAGC,YAAH,CAAgB,6CAAhB,EAA+D,MAA/D,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMgC,kBAAlB;AACAvD,gBAAYuB,MAAMiC,mBAAlB;AACAxD,gBAAYuB,MAAMkC,iBAAlB;AACAzD,gBAAYuB,MAAMmC,kBAAlB;AACA1D,gBAAYuB,MAAMS,SAAlB;AACD,GATD;AAUAd,KAAG,qBAAH,EAA0B,YAAW;AACnC,QAAIC,SAASC,GAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMS,SAAlB;AACD,GARD;AASAd,KAAG,8BAAH,EAAmC,YAAW;AAC5C,QAAIC,SAASC,GAAGC,YAAH,CAAgB,qCAAhB,EAAuD,MAAvD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAH4C,CAI5C;;AACAjB,gBAAYuB,MAAMiC,mBAAlB;AACAxD,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMc,iBAAlB;AACArC,gBAAYuB,MAAMoC,IAAlB;AACA3D,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMqC,GAAlB;AACA5D,gBAAYuB,MAAMqC,GAAlB;AACA5D,gBAAYuB,MAAMqC,GAAlB;AACD,GAdD;AAeA1C,KAAG,8CAAH,EAAmD,YAAW;AAC5D,QAAIC,SAASC,GAAGC,YAAH,CAAgB,yCAAhB,EAA2D,MAA3D,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB;AACA,sBAAOK,OAAOL,MAAP,CAAc4C,MAArB,EAA6BzD,EAA7B,CAAgCW,KAAhC,CAAsC,CAAtC;AACAf,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMiC,mBAAlB;AACAxD,gBAAYuB,MAAMS,SAAlB;AACD,GARD;AASAd,KAAG,8BAAH,EAAmC,YAAW;AAC5C,QAAIC,SAASC,GAAGC,YAAH,CAAgB,2CAAhB,EAA6D,MAA7D,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAH4C,CAI5C;AACA;;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACAzC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMmB,eAAlB;AACA1C,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMoB,cAAlB;AACA3C,gBAAYuB,MAAMuB,YAAlB;AACA9C,gBAAYuB,MAAMmB,eAAlB;AACA1C,gBAAYuB,MAAMS,SAAlB;AACD,GAlBD;AAmBAd,KAAG,uBAAH,EAA4B,YAAW;AACrC,QAAIC,SAASC,GAAGC,YAAH,CAAgB,oCAAhB,EAAsD,MAAtD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAHqC,CAIrC;AACA;;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMuC,WAAlB;AACA9D,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMuC,WAAlB;AACA9D,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMuC,WAAlB;AACA9D,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMuC,WAAlB;AACA9D,gBAAYuB,MAAMuC,WAAlB;AACA9D,gBAAYuB,MAAMS,SAAlB;AACD,GAhBD;AAiBAd,KAAG,sCAAH,EAA2C,YAAW;AACpD,QAAIC,SAASC,GAAGC,YAAH,CAAgB,sCAAhB,EAAwD,MAAxD,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAHoD,CAIpD;;AACAV,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EANoD,CAMb;;AACvCA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,EAAvB,EAA2B,CAA3B,EAA8B,CAA9B,EAAiC,CAAjC,EAAoC,CAApC,EAToD,CASZ;;AACxCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAVoD,CAUX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC;AACAA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EAZoD,CAYT;;AAC3CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,CAAtC,EAboD,CAaV;;AAC1CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAdoD,CAcX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAfoD,CAeX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAhBoD,CAgBX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAjBoD,CAiBX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC;AACAA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAnBoD,CAmBX;;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,EAArC,EApBoD,CAoBV;;AAC1CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EArBoD,CAqBT;;AAC3CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EAtBoD,CAsBT;;AAC3CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EAvBoD,CAuBT;AAC5C,GAxBD;AAyBAW,KAAG,6DAAH,EAAkE,YAAW;AAC3E,QAAIC,SAASC,GAAGC,YAAH,CAAgB,uDAAhB,EAAyE,MAAzE,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAH2E,CAI3E;AACA;;AACAV,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EAN2E,CAMpC;;AACvCA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EAP2E,CAOpC;AACxC,GARD;AASAW,KAAG,mCAAH,EAAwC,YAAW;AACjD,QAAIC,SAASC,GAAGC,YAAH,CAAgB,+CAAhB,EAAiE,MAAjE,CAAb;AACA,QAAMC,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAHiD,CAIjD;AACA;;AACAjB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMe,MAAlB;AACAtC,gBAAYuB,MAAME,eAAlB;AACAzB,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMkB,MAAlB;AACD,GAZD;AAaAvB,KAAG,qBAAH,EAA0B,YAAW;AACnC,QAAIC,oFAAJ;AAOA,QAAMG,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EATmC,CAUnC;AACA;;AACAjB,gBAAYuB,MAAMwC,WAAlB;AACA/D,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMiC,mBAAlB;AACAxD,gBAAYuB,MAAMS,SAAlB;AACD,GAhBD;AAiBAd,KAAG,mBAAH,EAAwB,YAAW;AACjC,QAAIC,wMAAJ;AAWA,QAAMG,SAASC,MAAMC,QAAN,CAAeL,MAAf,CAAf;AACAH,cAAUM,OAAOL,MAAjB,EAbiC,CAcjC;AACA;;AACAjB,gBAAYuB,MAAMW,YAAlB;AACAlC,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMsB,QAAlB;AACA7C,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMiC,mBAAlB;AACAxD,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMsB,QAAlB;AACA7C,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMgC,kBAAlB;AACAvD,gBAAYuB,MAAMsB,QAAlB;AACA7C,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMmC,kBAAlB;AACA1D,gBAAYuB,MAAMS,SAAlB;AACAhC,gBAAYuB,MAAMsB,QAAlB;AACA7C,gBAAYuB,MAAMU,SAAlB;AACAjC,gBAAYuB,MAAMkC,iBAAlB;AACAzD,gBAAYuB,MAAMsB,QAAlB;AACD,GAjCD,EA7Y2B,CA+a3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACD,CA3bD","sourcesContent":["import { describe } from \"mocha\";\nimport { expect } from \"chai\";\nimport * as fs from \"fs\";\nimport * as lexer from \"../src/lexer\";\nimport * as chevrotain from \"chevrotain\";\n\nlet i = 0;\nlet currentTokens: chevrotain.IToken[] = [];\nfunction expectToken(tokenType: chevrotain.TokenType) {\n  //expect(currentTokens[i]).to.be.an.instanceof(tokenType);\n  expect(chevrotain.tokenMatcher(currentTokens[i], tokenType)).to.be.true;\n  i++;\n}\nfunction expectTokenLocation(\n  startOffset: number,\n  endOffset: number,\n  startLine: number,\n  endLine: number,\n  startColumn: number,\n  endColumn: number\n) {\n  var token = currentTokens[i];\n  expect(token.startOffset).to.equal(startOffset);\n  expect(token.endOffset).to.equal(endOffset);\n  expect(token.startLine).to.equal(startLine);\n  expect(token.endLine).to.equal(endLine);\n  expect(token.startColumn).to.equal(startColumn);\n  expect(token.endColumn).to.equal(endColumn);\n  i++;\n}\nfunction startTest(tokens: chevrotain.IToken[]) {\n  currentTokens = tokens;\n  i = 0;\n}\n\ndescribe(\"Lexer\", function() {\n  it(\"recognizes incoming and outgoing relations\", function() {\n    let source = fs.readFileSync(\"./test/lexer-relations.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    //console.log(lexer.tokensToString(result.tokens));\n    startTest(result.tokens);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.IncomingAttack);\n    expectToken(lexer.Contradiction);\n    expectToken(lexer.IncomingUndercut);\n    expectToken(lexer.OutgoingUndercut);\n  });\n  it(\"can distinguish between Emptyline and Newline\", function() {\n    let source = fs.readFileSync(\"./test/lexer-emptyline.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex mentions\", function() {\n    let source = fs.readFileSync(\"./test/lexer-mentions.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n  });\n  it(\"can lex headings\", function() {\n    let source = fs.readFileSync(\"./test/lexer-heading.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex ordered and unordered lists\", function() {\n    let source = fs.readFileSync(\"./test/lexer-lists.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    // console.log(lexer.tokensToString(result.tokens));\n    startTest(result.tokens);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex an argument reconstruction\", function() {\n    let source = fs.readFileSync(\"./test/lexer-argument.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    // console.log(lexer.tokensToString(result.tokens));\n    startTest(result.tokens);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.InferenceStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetaData);\n    expectToken(lexer.InferenceEnd);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can dedent on Emptyline\", function() {\n    let source = fs.readFileSync(\"./test/lexer-emptyline-dedent.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore Newlines in relations\", function() {\n    let source = fs.readFileSync(\"./test/lexer-linebreak.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex bold and italic text\", function() {\n    let source = fs.readFileSync(\"./test/lexer-italic-bold.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    // console.log(lexer.tokensToString(result.tokens));\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n  });\n  it(\"can lex complex indentation\", function() {\n    let source = fs.readFileSync(\"./test/lexer-indentation.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.IncomingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can recognize argument and statement references and definitions\", function() {\n    let source = fs.readFileSync(\"./test/lexer-definitions-references.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.StatementReference);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.ArgumentReference);\n    expectToken(lexer.ArgumentDefinition);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore comments\", function() {\n    let source = fs.readFileSync(\"./test/lexer-comment.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can recognize links and tags\", function() {\n    let source = fs.readFileSync(\"./test/lexer-links-and-tags.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.Link);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Tag);\n    expectToken(lexer.Tag);\n    expectToken(lexer.Tag);\n  });\n  it(\"can ignore trailing Emptyline before comment\", function() {\n    let source = fs.readFileSync(\"./test/lexer-trailing-emptyline.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expect(result.tokens.length).to.equal(3);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex Windows line endings\", function() {\n    let source = fs.readFileSync(\"./test/lexer-windows-line-endings.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.InferenceStart);\n    expectToken(lexer.InferenceEnd);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex escaped chars\", function() {\n    let source = fs.readFileSync(\"./test/lexer-escaped-chars.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can save correct token location data\", function() {\n    let source = fs.readFileSync(\"./test/lexer-token-locations.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokenLocationsToString(result.tokens));\n    expectTokenLocation(0, 0, 1, 1, 1, 1);\n    expectTokenLocation(2, 2, 2, 2, 1, 1); //offset = 2 because of ignored line break\n    expectTokenLocation(4, 5, 3, 3, 1, 2);\n    expectTokenLocation(6, 6, 3, 3, 3, 3);\n    expectTokenLocation(7, 11, 3, 3, 4, 8); //@[A]\n    expectTokenLocation(12, 12, 3, 3, 9, 9); //ItalicStart\n    expectTokenLocation(13, 13, 3, 3, 10, 10);\n    expectTokenLocation(14, 14, 3, 3, 11, 11); //ItalicEnd\n    expectTokenLocation(15, 16, 3, 4, 12, 1); //Emptyline\n    expectTokenLocation(17, 20, 5, 5, 1, 4); //<B>:\n    expectTokenLocation(22, 22, 5, 5, 6, 6); //skipped whitespace at offset 21\n    expectTokenLocation(24, 27, 6, 6, 1, 4); // Indent (4 spaces)\n    expectTokenLocation(24, 28, 6, 6, 1, 5); // + (including 4 spaces for indentation)\n    expectTokenLocation(30, 30, 6, 6, 7, 7);\n    expectTokenLocation(32, 39, 7, 7, 1, 8); // Indent (8 spaces)\n    expectTokenLocation(32, 41, 7, 7, 1, 10); // -> including spaces\n    expectTokenLocation(43, 43, 7, 7, 12, 12); // skipped whitespace at offset 42\n    expectTokenLocation(43, 43, 7, 7, 12, 12); // Dedent is always at last column of current line\n    expectTokenLocation(43, 43, 7, 7, 12, 12); // Dedent is always at last column of current line\n  });\n  it(\"can save correct token location data if first line is empty\", function() {\n    let source = fs.readFileSync(\"./test/lexer-token-locations-first-line-empty.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokenLocationsToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectTokenLocation(1, 1, 2, 2, 1, 1); //First newline skipped\n    expectTokenLocation(3, 3, 3, 3, 1, 1); //Second newline skipped\n  });\n  it(\"can lex relation after empty line\", function() {\n    let source = fs.readFileSync(\"./test/lexer-relation-after-emptyline.argdown\", \"utf8\");\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex frontmatter\", function() {\n    let source = `\n    ===\n    some: front matter\n    ===\n    \n    [title]: text\n    `;\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.FrontMatter);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex meta data\", function() {\n    let source = `\n    # heading {some: meta data}\n\n    [title]: text {some: meta data}\n\n    [title] {some: meta data}\n\n    <argument>: text {some: meta data}\n\n    <argument> {some: meta data}\n    `;\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    // console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetaData);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetaData);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementReference);\n    expectToken(lexer.MetaData);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.ArgumentDefinition);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetaData);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.ArgumentReference);\n    expectToken(lexer.MetaData);\n  });\n  // it(\"can lex statement references, definitions and mentions by number\", function () {\n  //   let source = fs.readFileSync(\"./test/lexer-statements-by-number.argdown\", 'utf8');\n  //   const result = lexer.tokenize(source);\n  //   startTest(result.tokens);\n  //   console.log(lexer.tokensToString(result.tokens));\n  //   //expect(result.tokens.length).to.equal(5);\n  //   expectToken(lexer.StatementDefinitionByNumber);\n  //   expectToken(lexer.Freestyle);\n  //   expectToken(lexer.StatementReferenceByNumber);\n  //   expectToken(lexer.StatementMentionByNumber);\n  //   // expectToken(lexer.Dedent);\n  // });\n});\n"],"file":"lexer.spec.js"}