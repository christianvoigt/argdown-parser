{"version":3,"sources":["../../test/lexer.spec.js"],"names":["i","currentTokens","expectToken","tokenType","to","be","true","startTest","tokens","lexer","describe","it","source","readFileSync","result","tokenize","OutgoingSupport","OutgoingAttack","IncomingSupport","IncomingAttack","Freestyle","Emptyline","HeadingStart","ArgumentMention","StatementMention","UnusedControlChar","Indent","UnorderedListItem","OrderedListItem","Dedent","ArgumentStatementStart","InferenceStart","ListDelimiter","MetadataStart","Colon","MetadataStatementEnd","MetadataEnd","InferenceEnd","UnderscoreBoldStart","UnderscoreBoldEnd","UnderscoreItalicStart","UnderscoreItalicEnd","AsteriskBoldStart","AsteriskBoldEnd","AsteriskItalicStart","AsteriskItalicEnd","StatementReference","StatementDefinition","ArgumentReference","ArgumentDefinition","Link"],"mappings":";;AACA;;AACA;;;;AACA;;AACA;;;;AAJA;AAMA,IAAIA,IAAI,CAAR;AACA,IAAIC,gBAAgB,IAApB;AACA,SAASC,WAAT,CAAqBC,SAArB,EAA+B;AAC7B;AACA,oBAAO,8BAAaF,cAAcD,CAAd,CAAb,EAA8BG,SAA9B,CAAP,EAAiDC,EAAjD,CAAoDC,EAApD,CAAuDC,IAAvD;AACAN;AACD;AACD,SAASO,SAAT,CAAmBC,MAAnB,EAA0B;AACxBP,kBAAgBO,MAAhB;AACAR,MAAI,CAAJ;AACD;AACD,IAAMS,kCAAN;;AAGAC,SAAS,OAAT,EAAkB,YAAW;AAC3BC,KAAG,4CAAH,EAAiD,YAAU;AACzD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMQ,cAAlB;AACAf,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMQ,cAAlB;AACAf,gBAAYO,MAAMS,eAAlB;AACAhB,gBAAYO,MAAMU,cAAlB;AACD,GAVD;AAWAR,KAAG,+CAAH,EAAoD,YAAU;AAC5D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACD,GAVD;AAWAT,KAAG,kBAAH,EAAuB,YAAU;AAC/B,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMa,YAAlB;AACApB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMc,eAAlB;AACArB,gBAAYO,MAAMe,gBAAlB;AACAtB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMgB,iBAAlB;AACAvB,gBAAYO,MAAMc,eAAlB;AACArB,gBAAYO,MAAMe,gBAAlB;AACD,GAbD;AAcEb,KAAG,kBAAH,EAAuB,YAAU;AACjC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMa,YAAlB;AACApB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMa,YAAlB;AACApB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACD,GAbC;AAcFT,KAAG,qCAAH,EAA0C,YAAU;AAClD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMkB,iBAAlB;AACAzB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMkB,iBAAlB;AACAzB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMmB,eAAlB;AACA1B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMkB,iBAAlB;AACAzB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMoB,MAAlB;AACD,GAnCD;AAoCElB,KAAG,oCAAH,EAAyC,YAAU;AACnD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMqB,sBAAlB;AACA5B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMqB,sBAAlB;AACA5B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMsB,cAAlB;AACA7B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMuB,aAAlB;AACA9B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMwB,aAAlB;AACA/B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMyB,KAAlB;AACAhC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMuB,aAAlB;AACA9B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM0B,oBAAlB;AACAjC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMyB,KAAlB;AACAhC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMuB,aAAlB;AACA9B,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM2B,WAAlB;AACAlC,gBAAYO,MAAM4B,YAAlB;AACAnC,gBAAYO,MAAMqB,sBAAlB;AACA5B,gBAAYO,MAAMW,SAAlB;AACD,GA5BC;AA6BAT,KAAG,yBAAH,EAA6B,YAAU;AACvC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,uCAAhB,EAAyD,MAAzD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACD,GAXC;AAYFT,KAAG,kCAAH,EAAsC,YAAU;AAC9C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMQ,cAAlB;AACAf,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACD,GAhBD;AAiBAlB,KAAG,8BAAH,EAAkC,YAAU;AAC1C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM6B,mBAAlB;AACApC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM8B,iBAAlB;AACArC,gBAAYO,MAAM+B,qBAAlB;AACAtC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMgC,mBAAlB;AACAvC,gBAAYO,MAAMiC,iBAAlB;AACAxC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMkC,eAAlB;AACAzC,gBAAYO,MAAMmC,mBAAlB;AACA1C,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoC,iBAAlB;AACA3C,gBAAYO,MAAMiC,iBAAlB;AACAxC,gBAAYO,MAAMmC,mBAAlB;AACA1C,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoC,iBAAlB;AACA3C,gBAAYO,MAAMkC,eAAlB;AACAzC,gBAAYO,MAAM6B,mBAAlB;AACApC,gBAAYO,MAAM+B,qBAAlB;AACAtC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMgC,mBAAlB;AACAvC,gBAAYO,MAAM8B,iBAAlB;AACArC,gBAAYO,MAAM6B,mBAAlB;AACApC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMmC,mBAAlB;AACA1C,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoC,iBAAlB;AACA3C,gBAAYO,MAAM8B,iBAAlB;AACArC,gBAAYO,MAAMmC,mBAAlB;AACA1C,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM6B,mBAAlB;AACApC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAM8B,iBAAlB;AACArC,gBAAYO,MAAMoC,iBAAlB;AACA3C,gBAAYO,MAAMiC,iBAAlB;AACAxC,gBAAYO,MAAMiC,iBAAlB;AACAxC,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMkC,eAAlB;AACAzC,gBAAYO,MAAMkC,eAAlB;AACD,GA5CD;AA6CGhC,KAAG,6BAAH,EAAkC,YAAW;AAC7C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMQ,cAAlB;AACAf,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMO,eAAlB;AACAd,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMQ,cAAlB;AACAf,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMiB,MAAlB;AACAxB,gBAAYO,MAAMS,eAAlB;AACAhB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMoB,MAAlB;AACA3B,gBAAYO,MAAMU,cAAlB;AACAjB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMoB,MAAlB;AAED,GA1BC;AA2BFlB,KAAG,iEAAH,EAAsE,YAAU;AAC9E,QAAIC,SAAS,aAAGC,YAAH,CAAgB,6CAAhB,EAA+D,MAA/D,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMqC,kBAAlB;AACA5C,gBAAYO,MAAMsC,mBAAlB;AACA7C,gBAAYO,MAAMuC,iBAAlB;AACA9C,gBAAYO,MAAMwC,kBAAlB;AACA/C,gBAAYO,MAAMW,SAAlB;AACD,GATD;AAUAT,KAAG,qBAAH,EAA0B,YAAU;AAClC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMY,SAAlB;AACAnB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMW,SAAlB;AACD,GARD;AASAT,KAAG,qBAAH,EAA0B,YAAU;AAClC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAN,gBAAYO,MAAMsC,mBAAlB;AACA7C,gBAAYO,MAAMgB,iBAAlB;AACAvB,gBAAYO,MAAMW,SAAlB;AACAlB,gBAAYO,MAAMgB,iBAAlB;AACAvB,gBAAYO,MAAMyC,IAAlB;AACAhD,gBAAYO,MAAMW,SAAlB;AACD,GAVD;AAWD,CAvPF","file":"lexer.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from 'chai';\nimport fs from 'fs';\nimport {ArgdownLexer} from '../src/ArgdownLexer.js';\nimport {tokenMatcher} from 'chevrotain';\n\nlet i = 0;\nlet currentTokens = null;\nfunction expectToken(tokenType){\n  //expect(currentTokens[i]).to.be.an.instanceof(tokenType);\n  expect(tokenMatcher(currentTokens[i],tokenType)).to.be.true;\n  i++;\n}\nfunction startTest(tokens){\n  currentTokens = tokens;\n  i = 0;\n}\nconst lexer = ArgdownLexer;\n\n\ndescribe(\"Lexer\", function() {\n  it(\"recognizes incoming and outgoing relations\", function(){\n    let source = fs.readFileSync(\"./test/lexer-relations.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.IncomingAttack);\n  });\n  it(\"can distinguish between Emptyline and Newline\", function(){\n    let source = fs.readFileSync(\"./test/lexer-emptyline.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex mentions\", function(){\n    let source = fs.readFileSync(\"./test/lexer-mentions.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n  });\n    it(\"can lex headings\", function(){\n    let source = fs.readFileSync(\"./test/lexer-heading.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex ordered and unordered lists\", function(){\n    let source = fs.readFileSync(\"./test/lexer-lists.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n  });\n    it(\"can lex an argument reconstruction\", function(){\n    let source = fs.readFileSync(\"./test/lexer-argument.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.InferenceStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStatementEnd);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataEnd);\n    expectToken(lexer.InferenceEnd);\n    expectToken(lexer.ArgumentStatementStart);\n    expectToken(lexer.Freestyle);\n  });\n    it(\"can dedent on Emptyline\",function(){\n    let source = fs.readFileSync(\"./test/lexer-emptyline-dedent.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore Newlines in relations\",function(){\n    let source = fs.readFileSync(\"./test/lexer-linebreak.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex bold and italic text\",function(){\n    let source = fs.readFileSync(\"./test/lexer-italic-bold.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n  });\n     it(\"can lex complex indentation\", function() {\n     let source = fs.readFileSync(\"./test/lexer-indentation.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.OutgoingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.OutgoingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Indent);\n     expectToken(lexer.IncomingSupport);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.Dedent);\n     expectToken(lexer.IncomingAttack);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Dedent);\n\n   });\n   it(\"can recognize argument and statement references and definitions\", function(){\n     let source = fs.readFileSync(\"./test/lexer-definitions-references.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.StatementReference);\n     expectToken(lexer.StatementDefinition);\n     expectToken(lexer.ArgumentReference);\n     expectToken(lexer.ArgumentDefinition);\n     expectToken(lexer.Freestyle);\n   });\n   it(\"can ignore comments\", function(){\n     let source = fs.readFileSync(\"./test/lexer-comment.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Emptyline);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.Freestyle);\n   });\n   it(\"can recognize links\", function(){\n     let source = fs.readFileSync(\"./test/lexer-links.argdown\", 'utf8');\n     const result = lexer.tokenize(source);\n     startTest(result.tokens);\n     expectToken(lexer.StatementDefinition);\n     expectToken(lexer.UnusedControlChar);\n     expectToken(lexer.Freestyle);\n     expectToken(lexer.UnusedControlChar);\n     expectToken(lexer.Link);\n     expectToken(lexer.Freestyle);\n   });\n });\n"]}