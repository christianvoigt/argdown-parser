{"version":3,"sources":["../../test/lexer.spec.js"],"names":["i","currentTokens","expectToken","tokenType","to","be","true","expectTokenLocation","startOffset","endOffset","startLine","endLine","startColumn","endColumn","token","equal","startTest","tokens","lexer","describe","it","source","readFileSync","result","tokenize","OutgoingSupport","OutgoingAttack","IncomingSupport","IncomingAttack","Contradiction","IncomingUndercut","OutgoingUndercut","Freestyle","Emptyline","HeadingStart","ArgumentMention","StatementMention","UnusedControlChar","Indent","UnorderedListItem","OrderedListItem","Dedent","StatementNumber","InferenceStart","ListDelimiter","MetadataStart","Colon","MetadataStatementEnd","MetadataEnd","InferenceEnd","UnderscoreBoldStart","UnderscoreBoldEnd","UnderscoreItalicStart","UnderscoreItalicEnd","AsteriskBoldStart","AsteriskBoldEnd","AsteriskItalicStart","AsteriskItalicEnd","StatementReference","StatementDefinition","ArgumentReference","ArgumentDefinition","Link","Tag","length","EscapedChar","console","log","tokenLocationsToString"],"mappings":";;AACA;;AACA;;;;AACA;;AACA;;;;AAJA;AAMA,IAAIA,IAAI,CAAR;AACA,IAAIC,gBAAgB,IAApB;AACA,SAASC,WAAT,CAAqBC,SAArB,EAAgC;AAC9B;AACA,oBAAO,8BAAaF,cAAcD,CAAd,CAAb,EAA+BG,SAA/B,CAAP,EAAkDC,EAAlD,CAAqDC,EAArD,CAAwDC,IAAxD;AACAN;AACD;AACD,SAASO,mBAAT,CAA6BC,WAA7B,EAA0CC,SAA1C,EAAqDC,SAArD,EAAgEC,OAAhE,EAAyEC,WAAzE,EAAsFC,SAAtF,EAAgG;AAC9F,MAAIC,QAAQb,cAAcD,CAAd,CAAZ;AACA,oBAAOc,MAAMN,WAAb,EAA0BJ,EAA1B,CAA6BW,KAA7B,CAAmCP,WAAnC;AACA,oBAAOM,MAAML,SAAb,EAAwBL,EAAxB,CAA2BW,KAA3B,CAAiCN,SAAjC;AACA,oBAAOK,MAAMJ,SAAb,EAAwBN,EAAxB,CAA2BW,KAA3B,CAAiCL,SAAjC;AACA,oBAAOI,MAAMH,OAAb,EAAsBP,EAAtB,CAAyBW,KAAzB,CAA+BJ,OAA/B;AACA,oBAAOG,MAAMF,WAAb,EAA0BR,EAA1B,CAA6BW,KAA7B,CAAmCH,WAAnC;AACA,oBAAOE,MAAMD,SAAb,EAAwBT,EAAxB,CAA2BW,KAA3B,CAAiCF,SAAjC;AACAb;AACD;AACD,SAASgB,SAAT,CAAmBC,MAAnB,EAA2B;AACzBhB,kBAAgBgB,MAAhB;AACAjB,MAAI,CAAJ;AACD;AACD,IAAMkB,kCAAN;;AAGAC,SAAS,OAAT,EAAkB,YAAY;AAC5BC,KAAG,4CAAH,EAAiD,YAAY;AAC3D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMQ,cAAlB;AACAxB,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMQ,cAAlB;AACAxB,gBAAYgB,MAAMS,eAAlB;AACAzB,gBAAYgB,MAAMU,cAAlB;AACA1B,gBAAYgB,MAAMW,aAAlB;AACA3B,gBAAYgB,MAAMY,gBAAlB;AACA5B,gBAAYgB,MAAMa,gBAAlB;AACD,GAbD;AAcAX,KAAG,+CAAH,EAAoD,YAAY;AAC9D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACD,GAVD;AAWAZ,KAAG,kBAAH,EAAuB,YAAY;AACjC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMgB,YAAlB;AACAhC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMiB,eAAlB;AACAjC,gBAAYgB,MAAMkB,gBAAlB;AACAlC,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMiB,eAAlB;AACAjC,gBAAYgB,MAAMkB,gBAAlB;AACD,GAbD;AAcAhB,KAAG,kBAAH,EAAuB,YAAY;AACjC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMgB,YAAlB;AACAhC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMgB,YAAlB;AACAhC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACD,GAbD;AAcAZ,KAAG,qCAAH,EAA0C,YAAY;AACpD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,4BAAhB,EAA8C,MAA9C,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMqB,iBAAlB;AACArC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMqB,iBAAlB;AACArC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMsB,eAAlB;AACAtC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMqB,iBAAlB;AACArC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMuB,MAAlB;AACD,GAnCD;AAoCArB,KAAG,oCAAH,EAAyC,YAAY;AACnD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+BAAhB,EAAiD,MAAjD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMwB,eAAlB;AACAxC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMwB,eAAlB;AACAxC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMyB,cAAlB;AACAzC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM0B,aAAlB;AACA1C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM2B,aAAlB;AACA3C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM4B,KAAlB;AACA5C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM0B,aAAlB;AACA1C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM6B,oBAAlB;AACA7C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM4B,KAAlB;AACA5C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM0B,aAAlB;AACA1C,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM8B,WAAlB;AACA9C,gBAAYgB,MAAM+B,YAAlB;AACA/C,gBAAYgB,MAAMwB,eAAlB;AACAxC,gBAAYgB,MAAMc,SAAlB;AACD,GA5BD;AA6BAZ,KAAG,yBAAH,EAA8B,YAAY;AACxC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,uCAAhB,EAAyD,MAAzD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACD,GAXD;AAYAZ,KAAG,kCAAH,EAAuC,YAAY;AACjD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,gCAAhB,EAAkD,MAAlD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMQ,cAAlB;AACAxB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACD,GAhBD;AAiBArB,KAAG,8BAAH,EAAmC,YAAY;AAC7C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMiC,iBAAlB;AACAjD,gBAAYgB,MAAMkC,qBAAlB;AACAlD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmC,mBAAlB;AACAnD,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMqC,eAAlB;AACArD,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMqC,eAAlB;;AAEArD,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMkC,qBAAlB;AACAlD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmC,mBAAlB;AACAnD,gBAAYgB,MAAMiC,iBAAlB;;AAEAjD,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMiC,iBAAlB;AACAjD,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMiC,iBAAlB;AACAjD,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMqC,eAAlB;AACArD,gBAAYgB,MAAMqC,eAAlB;AACArD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMkC,qBAAlB;AACAlD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmC,mBAAlB;AACAnD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMqC,eAAlB;AACArD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMiC,iBAAlB;AACAjD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMsC,mBAAlB;AACAtD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuC,iBAAlB;AACAvD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMkC,qBAAlB;AACAlD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmC,mBAAlB;AACAnD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMoC,iBAAlB;AACApD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMqC,eAAlB;AACArD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMgC,mBAAlB;AACAhD,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMiC,iBAAlB;AACAjD,gBAAYgB,MAAMmB,iBAAlB;AACD,GAxFD;AAyFAjB,KAAG,6BAAH,EAAkC,YAAY;AAC5C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,kCAAhB,EAAoD,MAApD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMQ,cAAlB;AACAxB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMQ,cAAlB;AACAxB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMS,eAAlB;AACAzB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMuB,MAAlB;AACAvC,gBAAYgB,MAAMU,cAAlB;AACA1B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AAED,GA1BD;AA2BArB,KAAG,iEAAH,EAAsE,YAAY;AAChF,QAAIC,SAAS,aAAGC,YAAH,CAAgB,6CAAhB,EAA+D,MAA/D,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMwC,kBAAlB;AACAxD,gBAAYgB,MAAMyC,mBAAlB;AACAzD,gBAAYgB,MAAM0C,iBAAlB;AACA1D,gBAAYgB,MAAM2C,kBAAlB;AACA3D,gBAAYgB,MAAMc,SAAlB;AACD,GATD;AAUAZ,KAAG,qBAAH,EAA0B,YAAY;AACpC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,8BAAhB,EAAgD,MAAhD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMc,SAAlB;AACD,GARD;AASAZ,KAAG,8BAAH,EAAmC,YAAY;AAC7C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,qCAAhB,EAAuD,MAAvD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACAf,gBAAYgB,MAAMyC,mBAAlB;AACAzD,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMmB,iBAAlB;AACAnC,gBAAYgB,MAAM4C,IAAlB;AACA5D,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM6C,GAAlB;AACA7D,gBAAYgB,MAAM6C,GAAlB;AACA7D,gBAAYgB,MAAM6C,GAAlB;AACD,GAdD;AAeA3C,KAAG,8CAAH,EAAmD,YAAY;AAC7D,QAAIC,SAAS,aAAGC,YAAH,CAAgB,yCAAhB,EAA2D,MAA3D,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA,sBAAOM,OAAON,MAAP,CAAc+C,MAArB,EAA6B5D,EAA7B,CAAgCW,KAAhC,CAAsC,CAAtC;AACAb,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMyC,mBAAlB;AACAzD,gBAAYgB,MAAMc,SAAlB;AACD,GARD;AASAZ,KAAG,8BAAH,EAAmC,YAAY;AAC7C,QAAIC,SAAS,aAAGC,YAAH,CAAgB,2CAAhB,EAA6D,MAA7D,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACA;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACD,GAXD;AAYArB,KAAG,uBAAH,EAA4B,YAAY;AACtC,QAAIC,SAAS,aAAGC,YAAH,CAAgB,oCAAhB,EAAsD,MAAtD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACA;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM+C,WAAlB;AACA/D,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM+C,WAAlB;AACA/D,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM+C,WAAlB;AACA/D,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAM+C,WAAlB;AACA/D,gBAAYgB,MAAM+C,WAAlB;AACA/D,gBAAYgB,MAAMc,SAAlB;AACD,GAhBD;AAiBAZ,KAAG,sCAAH,EAA2C,YAAY;AACrD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,sCAAhB,EAAwD,MAAxD,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACAiD,YAAQC,GAAR,CAAYjD,MAAMkD,sBAAN,CAA6B7C,OAAON,MAApC,CAAZ;AACAV,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EANqD,CAMd;AACvCA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC;AACAA,wBAAoB,CAApB,EAAuB,EAAvB,EAA2B,CAA3B,EAA8B,CAA9B,EAAiC,CAAjC,EAAoC,CAApC,EATqD,CASb;AACxCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAVqD,CAUZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC;AACAA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EAZqD,CAYV;AAC3CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,CAAtC,EAbqD,CAaX;AAC1CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAdqD,CAcZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAfqD,CAeZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAhBqD,CAgBZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAjBqD,CAiBZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC;AACAA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAnBqD,CAmBZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,EAArC,EApBqD,CAoBX;AAC1CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,EAAlC,EAAsC,EAAtC,EArBqD,CAqBV;AAC3CA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAtBqD,CAsBZ;AACzCA,wBAAoB,EAApB,EAAwB,EAAxB,EAA4B,CAA5B,EAA+B,CAA/B,EAAkC,CAAlC,EAAqC,CAArC,EAvBqD,CAuBZ;AAC1C,GAxBD;AAyBAa,KAAG,6DAAH,EAAkE,YAAY;AAC5E,QAAIC,SAAS,aAAGC,YAAH,CAAgB,uDAAhB,EAAyE,MAAzE,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACA;AACAV,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EAN4E,CAMrC;AACvCA,wBAAoB,CAApB,EAAuB,CAAvB,EAA0B,CAA1B,EAA6B,CAA7B,EAAgC,CAAhC,EAAmC,CAAnC,EAP4E,CAOrC;AACxC,GARD;AASAa,KAAG,mCAAH,EAAwC,YAAY;AAClD,QAAIC,SAAS,aAAGC,YAAH,CAAgB,+CAAhB,EAAiE,MAAjE,CAAb;AACA,QAAMC,SAASL,MAAMM,QAAN,CAAeH,MAAf,CAAf;AACAL,cAAUO,OAAON,MAAjB;AACA;AACA;AACAf,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMe,SAAlB;AACA/B,gBAAYgB,MAAMoB,MAAlB;AACApC,gBAAYgB,MAAMO,eAAlB;AACAvB,gBAAYgB,MAAMc,SAAlB;AACA9B,gBAAYgB,MAAMuB,MAAlB;AACD,GAZD;AAaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAED,CA5YD","file":"lexer.spec.js","sourcesContent":["//import { before, after, describe, it } from 'mocha';\nimport { expect } from 'chai';\nimport fs from 'fs';\nimport { ArgdownLexer } from '../src/ArgdownLexer.js';\nimport { tokenMatcher } from 'chevrotain';\n\nlet i = 0;\nlet currentTokens = null;\nfunction expectToken(tokenType) {\n  //expect(currentTokens[i]).to.be.an.instanceof(tokenType);\n  expect(tokenMatcher(currentTokens[i], tokenType)).to.be.true;\n  i++;\n}\nfunction expectTokenLocation(startOffset, endOffset, startLine, endLine, startColumn, endColumn){\n  var token = currentTokens[i];\n  expect(token.startOffset).to.equal(startOffset);\n  expect(token.endOffset).to.equal(endOffset);\n  expect(token.startLine).to.equal(startLine);\n  expect(token.endLine).to.equal(endLine);\n  expect(token.startColumn).to.equal(startColumn);\n  expect(token.endColumn).to.equal(endColumn);\n  i++;\n}\nfunction startTest(tokens) {\n  currentTokens = tokens;\n  i = 0;\n}\nconst lexer = ArgdownLexer;\n\n\ndescribe(\"Lexer\", function () {\n  it(\"recognizes incoming and outgoing relations\", function () {\n    let source = fs.readFileSync(\"./test/lexer-relations.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.IncomingAttack);\n    expectToken(lexer.Contradiction);\n    expectToken(lexer.IncomingUndercut);\n    expectToken(lexer.OutgoingUndercut);\n  });\n  it(\"can distinguish between Emptyline and Newline\", function () {\n    let source = fs.readFileSync(\"./test/lexer-emptyline.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex mentions\", function () {\n    let source = fs.readFileSync(\"./test/lexer-mentions.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.ArgumentMention);\n    expectToken(lexer.StatementMention);\n  });\n  it(\"can lex headings\", function () {\n    let source = fs.readFileSync(\"./test/lexer-heading.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.HeadingStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex ordered and unordered lists\", function () {\n    let source = fs.readFileSync(\"./test/lexer-lists.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.OrderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.UnorderedListItem);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex an argument reconstruction\", function () {\n    let source = fs.readFileSync(\"./test/lexer-argument.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.InferenceStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataStatementEnd);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Colon);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.ListDelimiter);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.MetadataEnd);\n    expectToken(lexer.InferenceEnd);\n    expectToken(lexer.StatementNumber);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can dedent on Emptyline\", function () {\n    let source = fs.readFileSync(\"./test/lexer-emptyline-dedent.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore Newlines in relations\", function () {\n    let source = fs.readFileSync(\"./test/lexer-linebreak.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex bold and italic text\", function () {\n    let source = fs.readFileSync(\"./test/lexer-italic-bold.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    // console.log(lexer.tokensToString(result.tokens));\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreItalicStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreItalicEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.AsteriskBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.AsteriskBoldEnd);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.UnderscoreBoldStart);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnderscoreBoldEnd);\n    expectToken(lexer.UnusedControlChar);    \n  });\n  it(\"can lex complex indentation\", function () {\n    let source = fs.readFileSync(\"./test/lexer-indentation.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.IncomingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.Dedent);\n    expectToken(lexer.IncomingAttack);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n\n  });\n  it(\"can recognize argument and statement references and definitions\", function () {\n    let source = fs.readFileSync(\"./test/lexer-definitions-references.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.StatementReference);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.ArgumentReference);\n    expectToken(lexer.ArgumentDefinition);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can ignore comments\", function () {\n    let source = fs.readFileSync(\"./test/lexer-comment.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can recognize links and tags\", function () {\n    let source = fs.readFileSync(\"./test/lexer-links-and-tags.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.UnusedControlChar);\n    expectToken(lexer.Link);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Tag);\n    expectToken(lexer.Tag);\n    expectToken(lexer.Tag);\n  });\n  it(\"can ignore trailing Emptyline before comment\", function () {\n    let source = fs.readFileSync(\"./test/lexer-trailing-emptyline.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    expect(result.tokens.length).to.equal(3);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.StatementDefinition);\n    expectToken(lexer.Freestyle);\n  });\n  it(\"can lex Windows line endings\", function () {\n    let source = fs.readFileSync(\"./test/lexer-windows-line-endings.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  });\n  it(\"can lex escaped chars\", function () {\n    let source = fs.readFileSync(\"./test/lexer-escaped-chars.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.EscapedChar);\n    expectToken(lexer.Freestyle);  \n  });  \n  it(\"can save correct token location data\", function () {\n    let source = fs.readFileSync(\"./test/lexer-token-locations.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    console.log(lexer.tokenLocationsToString(result.tokens));\n    expectTokenLocation(0, 0, 1, 1, 1, 1);\n    expectTokenLocation(2, 2, 2, 2, 1, 1); //offset = 2 because of ignored line break\n    expectTokenLocation(4, 5, 3, 3, 1, 2);\n    expectTokenLocation(6, 6, 3, 3, 3, 3);\n    expectTokenLocation(7, 11, 3, 3, 4, 8); //@[A]\n    expectTokenLocation(12, 12, 3, 3, 9, 9); //ItalicStart\n    expectTokenLocation(13, 13, 3, 3, 10, 10);\n    expectTokenLocation(14, 14, 3, 3, 11, 11); //ItalicEnd\n    expectTokenLocation(15, 16, 3, 4, 12, 1); //Emptyline\n    expectTokenLocation(17, 20, 5, 5, 1, 4); //<B>:\n    expectTokenLocation(22, 22, 5, 5, 6, 6); //skipped whitespace at offset 21\n    expectTokenLocation(24, 27, 6, 6, 1, 4); // Indent (4 spaces)\n    expectTokenLocation(23, 28, 5, 6, 7, 5); // + (including linebreak and 4 spaces for indentation)\n    expectTokenLocation(30, 30, 6, 6, 7, 7); \n    expectTokenLocation(32, 39, 7, 7, 1, 8); // Indent (8 spaces)\n    expectTokenLocation(31, 41, 6, 7, 8, 10); // -> including linebreak and spaces\n    expectTokenLocation(43, 43, 7, 7, 12, 12); // skipped whitespace at offset 42\n    expectTokenLocation(44, 44, 8, 8, 1, 1); // Dedent is always at next line at column 1\n    expectTokenLocation(44, 44, 8, 8, 1, 1); // Dedent is always at next line at column 1\n  });\n  it(\"can save correct token location data if first line is empty\", function () {\n    let source = fs.readFileSync(\"./test/lexer-token-locations-first-line-empty.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokenLocationsToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectTokenLocation(1, 1, 2, 2, 1, 1); //First newline skipped\n    expectTokenLocation(3, 3, 3, 3, 1, 1); //Second newline skipped\n  });   \n  it(\"can lex relation after empty line\", function () {\n    let source = fs.readFileSync(\"./test/lexer-relation-after-emptyline.argdown\", 'utf8');\n    const result = lexer.tokenize(source);\n    startTest(result.tokens);\n    //console.log(lexer.tokensToString(result.tokens));\n    //expect(result.tokens.length).to.equal(5);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Emptyline);\n    expectToken(lexer.Indent);\n    expectToken(lexer.OutgoingSupport);\n    expectToken(lexer.Freestyle);\n    expectToken(lexer.Dedent);\n  }); \n  // it(\"can lex statement references, definitions and mentions by number\", function () {\n  //   let source = fs.readFileSync(\"./test/lexer-statements-by-number.argdown\", 'utf8');\n  //   const result = lexer.tokenize(source);\n  //   startTest(result.tokens);\n  //   console.log(lexer.tokensToString(result.tokens));\n  //   //expect(result.tokens.length).to.equal(5);\n  //   expectToken(lexer.StatementDefinitionByNumber);\n  //   expectToken(lexer.Freestyle);\n  //   expectToken(lexer.StatementReferenceByNumber);\n  //   expectToken(lexer.StatementMentionByNumber);\n  //   // expectToken(lexer.Dedent);\n  // });\n\n});\n"]}